{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8617f06c-58a8-4e3d-bdc2-baab89cd9d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f926d506-a328-4322-9c70-dbcf803de515",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a1b93c-3907-4df5-b08b-2a32175d8fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gdown 1mTGV-I_oIKR0WWn22tkofmIhIEdD1q_m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1426cbcf-744b-4c6b-a848-a94326c2ed28",
   "metadata": {},
   "outputs": [],
   "source": [
    "!unzip airfoils_dataset.zip "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c5c758-6da3-460d-b579-c9c6fc75fc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "\n",
    "import glob\n",
    "\n",
    "import copy\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import json \n",
    "\n",
    "import torch\n",
    "from torch_geometric.data import Dataset, download_url, Batch, DataLoader\n",
    "from torch_geometric.transforms import FaceToEdge\n",
    "\n",
    "from torch_geometric.transforms import Cartesian, GenerateMeshNormals\n",
    "\n",
    "class AirfoilsDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, dir_path, split=\"train\", samples_n=None, noise=False, zeros=False):\n",
    "        \n",
    "        super(AirfoilsDataset, self).__init__()\n",
    "        \n",
    "        self.noise = noise\n",
    "        self.zeros = zeros\n",
    "        \n",
    "        self.cartesian_coords = Cartesian()\n",
    "        self.normals = GenerateMeshNormals()\n",
    "        \n",
    "        self.dir_path = dir_path\n",
    "        self.split = split\n",
    "        fld_dir = os.path.join(dir_path, split, \"*\")\n",
    "        print(fld_dir)\n",
    "        self.filenames = glob.glob(fld_dir)\n",
    "        self.samples = [self.generate_sample(f) for f in self.filenames]\n",
    "            \n",
    "    def generate_sample(self, filename):\n",
    "        \n",
    "        sample = json.load(open(filename))\n",
    "        \n",
    "        pos = torch.tensor(sample[\"coords\"])\n",
    "        edge_index = torch.tensor([[i, (i+1) % len(pos)] for i in range(len(pos))]).T\n",
    "        drag = -sample[\"CL\"] / sample[\"CD\"]\n",
    "\n",
    "        graph = Data(x=pos, pos=pos, edge_index=edge_index, y=drag)\n",
    "        graph = Cartesian()(graph)\n",
    "        \n",
    "        return graph\n",
    "        \n",
    "    def len(self):\n",
    "        return len(self.filenames)\n",
    "    \n",
    "    def get(self, idx):\n",
    "        \n",
    "        graph = copy.copy(self.samples[idx])\n",
    "        \n",
    "        if self.noise:\n",
    "            N = 500 # 150\n",
    "            vertices_number = graph.x.shape[0]\n",
    "            eps = random.choice([0, 0, 0, 1]) * float(not self.zeros)\n",
    "            y = torch.tensor(graph.y).tile([vertices_number, 1]) * eps + 100 * (1 - eps) # 150\n",
    "            graph.x = torch.cat([graph.x, y / N], dim=1) \n",
    "#             graph.x = torch.cat([graph.x, 0.1 * torch.ones_like(y)], dim=1) \n",
    "        \n",
    "            # get rid of me in case\n",
    "#             graph.y = graph.y * (1 - eps) + 0 * eps\n",
    "            \n",
    "        return graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a243c10d-3873-4df5-814b-9023ea189f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"airfoils_dataset\"\n",
    "dataset = AirfoilsDataset(path, \"train\")\n",
    "\n",
    "noise_dataset = AirfoilsDataset(path, \"train\", noise=True)\n",
    "\n",
    "test_dataset = AirfoilsDataset(path, \"test\")\n",
    "\n",
    "noise_test_dataset = AirfoilsDataset(path, \"test\", noise=True, zeros=True)\n",
    "\n",
    "ood_dataset = AirfoilsDataset(path, \"ood\")\n",
    "\n",
    "noise_ood_dataset = AirfoilsDataset(path, \"ood\", noise=True, zeros=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aa67a5-8087-4175-af36-c89a3551a727",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool, GMMConv\n",
    "\n",
    "from typing import Callable, Optional, Union\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing\n",
    "from torch_geometric.nn.inits import reset\n",
    "from torch_geometric.typing import (\n",
    "    Adj,\n",
    "    OptTensor,\n",
    "    PairOptTensor,\n",
    "    PairTensor,\n",
    "    SparseTensor,\n",
    "    torch_sparse,\n",
    ")\n",
    "from torch_geometric.utils import add_self_loops, remove_self_loops\n",
    "\n",
    "\n",
    "class PointNetConv(MessagePassing):\n",
    "    def __init__(self, local_nn: Optional[Callable] = None,\n",
    "                 global_nn: Optional[Callable] = None,\n",
    "                 add_self_loops: bool = True, **kwargs):\n",
    "        kwargs.setdefault('aggr', 'max')\n",
    "        super().__init__(**kwargs)\n",
    "\n",
    "        self.local_nn = local_nn\n",
    "        self.global_nn = global_nn\n",
    "        self.add_self_loops = add_self_loops\n",
    "\n",
    "        self.reset_parameters()\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        super().reset_parameters()\n",
    "        reset(self.local_nn)\n",
    "        reset(self.global_nn)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        x: Union[OptTensor, PairOptTensor],\n",
    "        pos: Union[Tensor, PairTensor],\n",
    "        edge_index: Adj,\n",
    "    ) -> Tensor:\n",
    "\n",
    "        if not isinstance(x, tuple):\n",
    "            x = (x, None)\n",
    "\n",
    "        if isinstance(pos, Tensor):\n",
    "            pos = (pos, pos)\n",
    "\n",
    "        if self.add_self_loops:\n",
    "            if isinstance(edge_index, Tensor):\n",
    "                edge_index, _ = remove_self_loops(edge_index)\n",
    "                edge_index, _ = add_self_loops(\n",
    "                    edge_index, num_nodes=min(pos[0].size(0), pos[1].size(0)))\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                edge_index = torch_sparse.set_diag(edge_index)\n",
    "\n",
    "        # propagate_type: (x: PairOptTensor, pos: PairTensor)\n",
    "        out = self.propagate(edge_index, x=x, pos=pos)\n",
    "\n",
    "        if self.global_nn is not None:\n",
    "            out = self.global_nn(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "    def message(self, x_j: Optional[Tensor], pos_i: Tensor, pos_j: Tensor) -> Tensor:\n",
    "        msg = pos_j - pos_i\n",
    "        if x_j is not None:\n",
    "            msg = torch.cat([x_j, msg], dim=1)\n",
    "        if self.local_nn is not None:\n",
    "            msg = self.local_nn(msg)\n",
    "        return msg\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return (f'{self.__class__.__name__}(local_nn={self.local_nn}, '\n",
    "                f'global_nn={self.global_nn})')\n",
    "\n",
    "\n",
    "import torch_geometric.nn\n",
    "from torch.nn import Linear, ReLU, LeakyReLU, ELU, Dropout\n",
    "\n",
    "from torch_geometric.nn import Sequential, GCNConv, GMMConv\n",
    "\n",
    "activation = torch.nn.ReLU\n",
    "\n",
    "def block(n_channels=12):\n",
    "\n",
    "    return Sequential('x, edge_index, edge_attr',  [\n",
    "        (GMMConv(n_channels, n_channels, 2, 2), 'x, edge_index, edge_attr -> x'),\n",
    "        activation(inplace=True),\n",
    "        (GMMConv(n_channels, 2*n_channels, 2, 2), 'x, edge_index, edge_attr -> x'),\n",
    "        activation(inplace=True),\n",
    "        (GMMConv(2*n_channels, 2*n_channels, 2, 2), 'x, edge_index, edge_attr -> x'),\n",
    "        activation(inplace=True),\n",
    "        (GMMConv(2*n_channels, 2*n_channels, 2, 2), 'x, edge_index, edge_attr -> x'),\n",
    "        activation(inplace=True),\n",
    "        (GMMConv(2*n_channels, n_channels, 2, 2), 'x, edge_index, edge_attr -> x'),\n",
    "        activation(inplace=True),\n",
    "    ])\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    \n",
    "    def __init__(self, channels=64, dropout=0., input_channels=2):\n",
    "        \n",
    "        super(Net, self).__init__()\n",
    "        \n",
    "        self.dropout = dropout\n",
    "        \n",
    "        CH = channels\n",
    "        self.conv1 = GMMConv(input_channels, CH, 2, 2)\n",
    "        \n",
    "        self.block1 = block(CH)\n",
    "        self.block2 = block(CH)\n",
    "        self.block3 = block(CH)\n",
    "        self.block4 = block(CH)\n",
    "        self.block5 = block(CH)\n",
    "        \n",
    "        self.conv_final = GMMConv(CH, CH, 2, 2)\n",
    "        \n",
    "        self.fc1 = torch.nn.Linear(CH, CH)\n",
    "        self.fc2 = torch.nn.Linear(CH, CH)\n",
    "        self.fc3 = torch.nn.Linear(CH, CH)\n",
    "        self.fc4 = torch.nn.Linear(CH, 1)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, data, features=False):\n",
    "        \n",
    "        x, edge_index, edge_attr, batch = data.x, data.edge_index, data.edge_attr, data.batch\n",
    "        \n",
    "        x = F.elu(self.conv1(x, edge_index, edge_attr))\n",
    "        \n",
    "        x = self.block1(x, edge_index, edge_attr)\n",
    "        x = self.block2(x, edge_index, edge_attr)# + x\n",
    "        x = self.block3(x, edge_index, edge_attr)# + x\n",
    "        x = self.block4(x, edge_index, edge_attr)# + x\n",
    "        x = self.block5(x, edge_index, edge_attr)# + x\n",
    "        \n",
    "        x = self.conv_final(x, edge_index, edge_attr)\n",
    "        feat = global_mean_pool(x, batch)\n",
    "        \n",
    "        x = self.activation(self.fc1(feat))\n",
    "        \n",
    "        x = torch.nn.functional.dropout(self.activation(self.fc2(x)), p=self.dropout, training=True)\n",
    "        x = torch.nn.functional.dropout(self.activation(self.fc3(x)), p=self.dropout, training=True)\n",
    "\n",
    "        if features:\n",
    "            return self.fc4(x), feat\n",
    "        \n",
    "        return self.fc4(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb398616-f5ed-4567-8cb6-41f146e8a331",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.makedirs(\"weights\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c76de4a-85af-45b6-a9e8-55a07def646e",
   "metadata": {},
   "source": [
    "# Train Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f09916a-c8a8-41db-8b33-aea326b8cd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import random\n",
    "\n",
    "for r in [16]:\n",
    "\n",
    "    lr = 1e-3\n",
    "    epochs = 10\n",
    "    device = \"cuda\"\n",
    "    batch_size = 128\n",
    "\n",
    "    random_seed = r\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.manual_seed(random_seed)\n",
    "\n",
    "    torch.manual_seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "\n",
    "    model = Net(64).cuda()\n",
    "    dataloader = DataLoader(dataset, batch_size)\n",
    "    test_loader = DataLoader(test_dataset, 1)\n",
    "    ood_loader = DataLoader(ood_dataset, 1)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        res = []\n",
    "        t = tqdm.trange(len(dataset) // batch_size + 1, desc='Current Loss = ', leave=True)\n",
    "\n",
    "        for _, batch in zip(t, dataloader):\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y = model(batch)\n",
    "\n",
    "            loss = F.mse_loss(y, batch.y[:, None])\n",
    "\n",
    "            metric = torch.abs(y[:, 0].detach().cpu() - batch.y.cpu()).mean().numpy()\n",
    "            res.append(metric)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_description(f\"Current Loss = {sum(res) / len(res)}\", refresh=True)\n",
    "\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = 1e-4\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        res = []\n",
    "        t = tqdm.trange(len(dataset) // batch_size + 1, desc='Current Loss = ', leave=True)\n",
    "\n",
    "        for _, batch in zip(t, dataloader):\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y = model(batch)\n",
    "\n",
    "            loss = F.mse_loss(y, batch.y[:, None])\n",
    "\n",
    "            metric = torch.abs(y[:, 0].detach().cpu() - batch.y.cpu()).mean().numpy()\n",
    "            res.append(metric)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_description(f\"Current Loss = {sum(res) / len(res)}\", refresh=True)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"./weights/single_model_{random_seed}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec919101-9b49-410a-92d7-fc1c1e2acd9c",
   "metadata": {},
   "source": [
    "# ZigZag Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f936ee84-78a6-4241-b334-5b8bc0b042f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import os\n",
    "import random\n",
    "\n",
    "for r in range(16, 17):\n",
    "\n",
    "    lr = 1e-3\n",
    "    epochs = 10\n",
    "    device = \"cuda\"\n",
    "    batch_size = 128\n",
    "\n",
    "    random_seed = r\n",
    "    torch.use_deterministic_algorithms(False, warn_only=True)\n",
    "    torch.backends.cudnn.enabled = False\n",
    "    torch.manual_seed(random_seed)\n",
    "    random.seed(random_seed)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    #     model = Net(64, 0.0, 2).cuda()\n",
    "    #     dataloader = DataLoader(dataset, batch_size)\n",
    "    #     test_loader = DataLoader(test_dataset, 1)\n",
    "    #     ood_loader = DataLoader(ood_dataset, 1)\n",
    "\n",
    "    model = Net(64, 0.0, 3).cuda()\n",
    "    dataloader = DataLoader(noise_dataset, batch_size)\n",
    "\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        res = []\n",
    "        t = tqdm.trange(len(dataset) // batch_size + 1, desc='Current Loss = ', leave=True)\n",
    "\n",
    "        for _, batch in zip(t, dataloader):\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y = model(batch)\n",
    "\n",
    "            loss = F.mse_loss(y, batch.y[:, None])\n",
    "\n",
    "            mask = batch.y != 0\n",
    "            metric = torch.abs(y[:, 0][mask].detach().cpu() - batch.y[mask].cpu()).mean().numpy()\n",
    "            res.append(metric)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_description(f\"Current Loss = {sum(res) / len(res)}\", refresh=True)\n",
    "\n",
    "    for g in optimizer.param_groups:\n",
    "        g['lr'] = 1e-4\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        res = []\n",
    "        t = tqdm.trange(len(dataset) // batch_size + 1, desc='Current Loss = ', leave=True)\n",
    "\n",
    "        for _, batch in zip(t, dataloader):\n",
    "            batch = batch.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            y = model(batch)\n",
    "\n",
    "            loss = F.mse_loss(y, batch.y[:, None])\n",
    "\n",
    "            mask = batch.y != 0\n",
    "            metric = torch.abs(y[:, 0][mask].detach().cpu() - batch.y[mask].cpu()).mean().numpy()\n",
    "            res.append(metric)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            t.set_description(f\"Current Loss = {sum(res) / len(res)}\", refresh=True)\n",
    "\n",
    "    torch.save(model.state_dict(), f\"./weights/zigzag_{random_seed}.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc840d34-b3d1-4693-99b5-b6e7c0b9866c",
   "metadata": {},
   "source": [
    "# Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a95edb-0bf8-456f-9d63-0c99157467f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import time \n",
    "\n",
    "def test(model, loader):\n",
    "    \n",
    "    t = tqdm.trange(len(loader), desc='Current Loss = ', leave=True)\n",
    "    \n",
    "    errors = []\n",
    "    for _, batch in zip(t, loader):\n",
    "        s = time.time()\n",
    "        pred_y = model(batch.cuda())\n",
    "        mae = float(torch.abs(pred_y.detach().cpu() - batch.y.cpu()).numpy())\n",
    "        errors.append(mae)\n",
    "        t.set_description(f\"Current Loss = {sum(errors) / len(errors)}\", refresh=True)\n",
    "\n",
    "    return errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a34b7c98-da76-49b2-a104-a19d65881bcc",
   "metadata": {},
   "source": [
    "## Vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf8ffbc-4f29-4197-905a-0ab3ebd7315f",
   "metadata": {},
   "outputs": [],
   "source": [
    "network = Net(64).cuda()\n",
    "\n",
    "network.load_state_dict(torch.load(f\"./weights/single_model_16.pth\"))\n",
    "network = network.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55ede8-4548-4c94-bc88-ee80f6305aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = test(network, test_loader)\n",
    "print(\"TEST SET MAE: \", np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ba97d96-5a8a-4e13-8d02-f6efde18b8a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = test(network, ood_loader)\n",
    "print(\"OOD SET MAE: \", np.mean(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4335589-0f60-4979-aa20-5e22c2585083",
   "metadata": {},
   "source": [
    "## ZigZag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abf86610-debe-4354-b7f2-e867c6681a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "znetwork = Net(64, 0.0, 3).cuda()\n",
    "znetwork.load_state_dict(torch.load(f\"./weights/zigzag_16.pth\"))\n",
    "znetwork = znetwork.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56b24424-7784-46fd-a39d-16440e66c393",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_test_loader = DataLoader(noise_test_dataset, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02563c6d-2a5c-4c9b-896d-b65e97193e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = test(znetwork, noise_test_loader)\n",
    "print(\"TEST SET MAE: \", np.mean(errors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33fe03f0-5e5d-48ed-96d9-430cbf10cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = test(znetwork,  DataLoader(noise_ood_dataset, 1))\n",
    "print(\"OOD SET MAE: \", np.mean(errors))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92a2bcfd-0bd9-4c1d-a9b4-935f294f7d63",
   "metadata": {},
   "source": [
    "# ITTT Optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9ba2ff7-95ef-4cf9-a73a-826822689b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torch.optim as optim\n",
    "import time\n",
    "\n",
    "def noise_uncertainty(model, model_original, data):\n",
    "    y_1 = model(data.cuda())\n",
    "    copy_data = deepcopy(data)\n",
    "    batch_mask = data.batch\n",
    "    \n",
    "    for i in range(len(y_1)):\n",
    "        copy_data.x[batch_mask == i, 2] = y_1[i] / 500.0\n",
    "        \n",
    "    y_2 = model_original(copy_data.cuda())\n",
    "    return (y_1 - y_2).abs().mean(), y_2, y_1\n",
    "\n",
    "def js_div(p, q):\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * (F.kl_div(torch.log(p), m, reduction='batchmean') +\n",
    "                  F.kl_div(torch.log(q), m, reduction='batchmean'))\n",
    "\n",
    "def ttt_one_instance(x, f_ttt, f, optimizer, n_steps, n_classes=10):\n",
    "  f_ttt.load_state_dict(f.state_dict())  # reset f_ttt to f\n",
    "  f_ttt.train()\n",
    "  f.eval()\n",
    "  for step in range(n_steps):\n",
    "    loss, y_1, y_2 = noise_uncertainty(f_ttt, f, x)\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  f_ttt.eval()\n",
    "  _, y_1, y_2 = noise_uncertainty(f_ttt, f, x)\n",
    "  return y_1, y_2\n",
    "\n",
    "\n",
    "def ttt(f, test_loader, n_steps, lr):\n",
    "    f_ttt = deepcopy(f)\n",
    "    f.eval()\n",
    "    optimizer = optim.Adam(f_ttt.parameters(), lr=lr)\n",
    "\n",
    "    t = tqdm.trange(len(test_loader), desc='Current Loss = ', leave=True)\n",
    "    errors = []\n",
    "    targets = []\n",
    "    for _, batch in zip(t, test_loader):\n",
    "        s = time.time()\n",
    "        y_hat_1, y_hat_2 = ttt_one_instance(batch, f_ttt, f, optimizer, n_steps)\n",
    "        mae = torch.abs(y_hat_2[:, 0].detach().cpu() - batch.y.cpu()).numpy().ravel().tolist()\n",
    "        targets += batch.y.ravel().tolist()\n",
    "        errors += mae #.append(mae)\n",
    "        t.set_description(f\"Current Loss = {sum(errors) / len(errors)}\", refresh=True)\n",
    "\n",
    "    return np.array(errors), np.array(targets)\n",
    "\n",
    "def vanilla_eval(f, test_loader):\n",
    "    f.eval()\n",
    "    t = tqdm.trange(len(test_loader), desc='Current Loss = ', leave=True)\n",
    "    errors = []\n",
    "    targets = []\n",
    "    for _, batch in zip(t, test_loader):\n",
    "        s = time.time()\n",
    "        batch = batch.cuda()\n",
    "        y_hat = f(batch)\n",
    "        mae = torch.abs(y_hat[:, 0].detach().cpu() - batch.y.cpu()).numpy().ravel().tolist()\n",
    "        targets += batch.y.ravel().tolist()\n",
    "        errors += mae #.append(mae)\n",
    "        t.set_description(f\"Current Loss = {sum(errors) / len(errors)}\", refresh=True)\n",
    "\n",
    "    return np.array(errors), np.array(targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0766dd14-1358-4881-932f-775c9d32e29a",
   "metadata": {},
   "source": [
    "# Vanilla OOD Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc382324-45e8-4030-b946-8315fa3092c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors, targets = vanilla_eval(network, ood_loader)\n",
    "\n",
    "errs = []\n",
    "for i in range(5):\n",
    "    q1, q2 = np.quantile(targets, q=0.2 * i), np.quantile(targets, q=0.2 * (i + 1))\n",
    "    mask = np.logical_and(targets >= q1, targets <= q2)\n",
    "    err = errors[mask].tolist()\n",
    "    errs.append(err)\n",
    "\n",
    "NOT_OPTIMIZED = [s for t in errs[::-1][:-1] for s in t]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81789734-8d07-4fc7-9a69-d126aaf36d50",
   "metadata": {},
   "source": [
    "# ITTT OOD Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a74a89-c022-4d88-b471-c41f0f88fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ittt_results = {}\n",
    "for bs in [2, 4, 16]:\n",
    "\n",
    "    errors, targets = ttt(znetwork, DataLoader(noise_ood_dataset, bs), n_steps=1, lr=2e-4) # PROPER SETUP FROM PAPER\n",
    "    \n",
    "    errs = []\n",
    "    for i in range(5):\n",
    "        q1, q2 = np.quantile(targets, q=0.2 * i), np.quantile(targets, q=0.2 * (i + 1))\n",
    "        mask = np.logical_and(targets >= q1, targets <= q2)\n",
    "        err = errors[mask].tolist()\n",
    "        errs.append(err)\n",
    "    \n",
    "    ittt_results[bs] = [s for t in errs[::-1][:-1] for s in t]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2fd49bd-fd23-4764-a632-c449ad2f8b36",
   "metadata": {},
   "source": [
    "# ActMAD OOD Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e62da8-6e77-4b40-9f41-2d66aea6abf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_ttt.engine.actmad_engine import ActMADEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a60e6ad-adab-4082-8e6f-6a395e1655df",
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = ActMADEngine(\n",
    "    network,\n",
    "    [\n",
    "        \"block1.module_8.aggr_module\",\n",
    "    ],\n",
    "    optimization_parameters={\n",
    "        \"lr\": 2e-4,\n",
    "        \"num_steps\": 1\n",
    "    }\n",
    ")\n",
    "\n",
    "train_dataloader = DataLoader(dataset, 16)\n",
    "engine.compute_statistics(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e58831b-50da-4bb9-9b18-7e0c39a659d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "actmad_results = {}\n",
    "\n",
    "for bs in [2, 4, 16]:\n",
    "    test_loader = DataLoader(ood_dataset, bs)\n",
    "    engine.eval()\n",
    "    t = tqdm.trange(len(test_loader), desc='Current Loss = ', leave=True)\n",
    "    errors = []\n",
    "    targets = []\n",
    "    for _, batch in zip(t, test_loader):\n",
    "        s = time.time()\n",
    "        batch = batch.cuda()\n",
    "        y_hat = engine(batch)\n",
    "        mae = torch.abs(y_hat[0][:, 0].detach().cpu() - batch.y.cpu()).numpy().ravel().tolist()\n",
    "        targets += batch.y.ravel().tolist()\n",
    "        errors += mae\n",
    "        t.set_description(f\"Current Loss = {sum(errors) / len(errors)}\", refresh=True)\n",
    "\n",
    "    targets, errors = np.array(targets), np.array(errors)\n",
    "\n",
    "    errs = []\n",
    "    for i in range(5):\n",
    "        q1, q2 = np.quantile(targets, q=0.2 * i), np.quantile(targets, q=0.2 * (i + 1))\n",
    "        mask = np.logical_and(targets >= q1, targets <= q2)\n",
    "        err = errors[mask].tolist()\n",
    "        errs.append(err)\n",
    "\n",
    "    actmad_results[bs] = [s for t in errs[::-1][:-1] for s in t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f5738f-b842-45d9-8714-a5596c657bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "MAE_2_batch = ittt_results[2]\n",
    "\n",
    "MAE_4_batch = ittt_results[4]\n",
    "\n",
    "MAE_16_batch = ittt_results[16]\n",
    "\n",
    "ActMAD_16_batch = actmad_results[16]\n",
    "\n",
    "ActMAD_4_batch = actmad_results[4]\n",
    "\n",
    "ActMAD_2_batch = actmad_results[2] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbd6be-01a5-4d8b-b839-349185cc7264",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "# Example extended data (more data points for each combination)\n",
    "\n",
    "fontsize = 20\n",
    "\n",
    "data = {\n",
    "    'Method': ['Not Optimized'] * len(NOT_OPTIMIZED) + ['ActMAD (batch=2)'] * len(ActMAD_2_batch) + ['ActMAD (batch=4)'] * len(ActMAD_4_batch) + ['ActMAD (batch=16)'] * len(ActMAD_16_batch) + ['$IT^3$ (batch=2)'] * len(MAE_2_batch) + ['$IT^3$ (batch=4)'] * len(MAE_4_batch) + [\"$IT^3$ (batch=16)\"] * len(MAE_16_batch),\n",
    "    'Out-of-distribution Level': ([1] * 58 + [2] * 57 + [3] * 58 + [4] * 57) * 7,\n",
    "    'Accuracy': NOT_OPTIMIZED + ActMAD_2_batch + ActMAD_4_batch + ActMAD_16_batch + MAE_2_batch + MAE_4_batch + MAE_16_batch\n",
    "}\n",
    "# Convert the dictionary to a Pandas DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "# Define custom colors for each method\n",
    "custom_palette = {\n",
    "    'Not Optimized': '#96CAC1',      # Green\n",
    "    'ActMAD (batch=2)': '#022db8e3',\n",
    "    'ActMAD (batch=4)': '#2647b5e3',\n",
    "    'ActMAD (batch=16)': '#475fade3',\n",
    "    '$IT^3$ (batch=2)': '#5304a8e3', # Yellow\n",
    "    '$IT^3$ (batch=4)': '#69349ee3',   # Violet\n",
    "    '$IT^3$ (batch=16)': '#7e5ca1e3'   # Red\n",
    "}\n",
    "# Create the seaborn boxplot with custom colors\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='Out-of-distribution Level', y='Accuracy', hue='Method', data=df, palette=custom_palette, showfliers=False)\n",
    "# Customize the plot\n",
    "# plt.title('Accuracy by Method and Severity', fontsize=fontsize)\n",
    "plt.xlabel('Out-of-distribution Level', fontsize=fontsize)\n",
    "plt.ylabel('MAE', fontsize=fontsize)\n",
    "plt.xticks(fontsize=fontsize)\n",
    "plt.yticks(fontsize=fontsize)\n",
    "plt.legend(fontsize=fontsize, ncol=3, framealpha=0.4)\n",
    "\n",
    "plt.grid(True, axis='y', linestyle='--') \n",
    "plt.gca().spines['top'].set_visible(False)\n",
    "plt.gca().spines['right'].set_visible(False)\n",
    "plt.gca().spines['left'].set_visible(False)\n",
    "plt.gca().spines['bottom'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "# plt.show()\n",
    "# plt.savefig(\"./viz/airfoils_ittt_results_box_updated.pdf\", format=\"pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1bf26a-88e5-4523-9fa2-68bc6e4f6c75",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ittt",
   "language": "python",
   "name": "ittt"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
