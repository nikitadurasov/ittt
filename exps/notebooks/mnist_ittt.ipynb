{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W5Jzaqkb-acN",
    "outputId": "404c3b90-6f88-46d9-faef-942446c8da9c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f7b59313bf0>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.nn.functional as F\n",
    "from copy import deepcopy\n",
    "\n",
    "n_epochs = 5 # number of epochs for training\n",
    "batch_size_train = 1024 # batch size for training\n",
    "batch_size_test = 8192 # batch size for testing\n",
    "learning_rate = 0.001 # learning rate for Adam\n",
    "log_interval = 10 # logging interval for metrics\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # device for computation\n",
    "\n",
    "# fixing random seed\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "id": "MsTQf0xB-jGr"
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.f1 = F1()\n",
    "        self.f2 = F2()\n",
    "    \n",
    "    def forward(self, x, y_hat, return_mid=False):\n",
    "        z = self.f1(x)\n",
    "        y_pred, z_pred  = self.f2(z, y_hat)\n",
    "        return y_pred, z_pred\n",
    "    \n",
    "    \n",
    "class F1(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(F1, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.activation = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.activation(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = self.activation(F.max_pool2d(self.conv2(x), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = self.activation(self.fc1(x))\n",
    "        return x\n",
    "    \n",
    "    \n",
    "class F2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(F2, self).__init__()\n",
    "        self.fc2 = nn.Linear(50, 50)\n",
    "        self.fc3 = nn.Linear(50, 60)\n",
    "        self.y_hat_fc = nn.Linear(10, 50)\n",
    "        self.activation = nn.LeakyReLU(negative_slope=0.01)\n",
    "\n",
    "    def forward(self, x, y_hat):\n",
    "        x = x + self.activation(self.y_hat_fc(y_hat))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x[:, :10].softmax(-1), x[:, 10:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "def js_div(p, q):\n",
    "    m = 0.5 * (p + q)\n",
    "    return 0.5 * (F.kl_div(torch.log(p), m, reduction='batchmean') + \n",
    "                  F.kl_div(torch.log(q), m, reduction='batchmean'))\n",
    "\n",
    "def train(f, train_loader, optimizer, n_epochs, n_classes=10):\n",
    "  f.train()\n",
    "  for epoch in range(1, n_epochs + 1):\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "      # randomally choose y0 to be either the true target y or a random class\n",
    "      x, y = data.to(device), target.to(device)\n",
    "      y0_d = y if torch.rand(1) > 0.25 else torch.randint(0, n_classes, (x.shape[0],), device=device)\n",
    "      y0 = F.one_hot(y0_d, num_classes=n_classes).float()\n",
    "\n",
    "      # forward pass\n",
    "      y1, z1 = f(x, y0)\n",
    "      y2, z2 = f.f2(z1, y1)\n",
    "\n",
    "      # losses\n",
    "      loss_supervised_1 = F.nll_loss(y1.log(), y)\n",
    "      loss_supervised_2 = F.nll_loss(y2.log(), y)\n",
    "      loss_unsupervised_y = js_div(y1, y2)*10\n",
    "      loss_unsupervised_z = (z1 - z2).pow(2).mean()*10\n",
    "      # loss = loss_supervised + #loss_unsupervised_y # + loss_unsupervised_z\n",
    "      loss = loss_supervised_1 + loss_supervised_2\n",
    "\n",
    "      # opt\n",
    "      optimizer.zero_grad()\n",
    "      loss.backward()\n",
    "      optimizer.step()\n",
    "\n",
    "      # log\n",
    "      if batch_idx % log_interval == 0:\n",
    "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tloss_supervised_1: {:.6f}, loss_supervised_2: {:.6f}'.format(\n",
    "          epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "          100. * batch_idx / len(train_loader), loss_supervised_1.item(), loss_supervised_2.item()))\n",
    "        torch.save(f.state_dict(), './model.pth')\n",
    "        torch.save(optimizer.state_dict(), './optimizer.pth')\n",
    "      \n",
    "\n",
    "def test(f, test_loader, n_classes=10, with_true_y=False):\n",
    "  f.eval()\n",
    "  test_loss, correct = 0, 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loader:\n",
    "      x, y = data.to(device), target.to(device)\n",
    "      if with_true_y:\n",
    "        y0 = F.one_hot(y, num_classes=n_classes).float()\n",
    "      else:\n",
    "        y0 = torch.ones((len(y), n_classes), device=x.device).to(device).softmax(-1)\n",
    "      y1, z1 = f(x, y0)\n",
    "      test_loss += F.nll_loss(y1.log(), y, size_average=False).item()\n",
    "      pred = y1.log().data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(y.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loader.dataset)\n",
    "  print(\"True y given\") if with_true_y else print(\"Max entropy given\")\n",
    "  print('\\nTest: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    test_loss, correct, len(test_loader.dataset),\n",
    "    100. * correct / len(test_loader.dataset)))\n",
    "  return 100 * correct / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A_IS4C6B_HMp",
    "outputId": "b5252423-4826-4d3a-bc1d-c84a04b8dd6c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max entropy given\n",
      "\n",
      "Test: Avg. loss: 2.3083, Accuracy: 1116/10000 (11%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tloss_supervised_1: 2.331868, loss_supervised_2: 2.319867\n",
      "Train Epoch: 1 [640/60000 (1%)]\tloss_supervised_1: 2.237945, loss_supervised_2: 2.291207\n",
      "Train Epoch: 1 [1280/60000 (2%)]\tloss_supervised_1: 1.901194, loss_supervised_2: 2.192133\n",
      "Train Epoch: 1 [1920/60000 (3%)]\tloss_supervised_1: 1.511952, loss_supervised_2: 1.883422\n",
      "Train Epoch: 1 [2560/60000 (4%)]\tloss_supervised_1: 0.863658, loss_supervised_2: 1.443065\n",
      "Train Epoch: 1 [3200/60000 (5%)]\tloss_supervised_1: 0.596709, loss_supervised_2: 0.893214\n",
      "Train Epoch: 1 [3840/60000 (6%)]\tloss_supervised_1: 0.480758, loss_supervised_2: 0.597582\n",
      "Train Epoch: 1 [4480/60000 (7%)]\tloss_supervised_1: 0.632129, loss_supervised_2: 0.694502\n",
      "Train Epoch: 1 [5120/60000 (9%)]\tloss_supervised_1: 0.619663, loss_supervised_2: 0.744345\n",
      "Train Epoch: 1 [5760/60000 (10%)]\tloss_supervised_1: 0.408254, loss_supervised_2: 0.531264\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tloss_supervised_1: 0.773556, loss_supervised_2: 0.713793\n",
      "Train Epoch: 1 [7040/60000 (12%)]\tloss_supervised_1: 0.368053, loss_supervised_2: 0.414351\n",
      "Train Epoch: 1 [7680/60000 (13%)]\tloss_supervised_1: 0.439157, loss_supervised_2: 0.595024\n",
      "Train Epoch: 1 [8320/60000 (14%)]\tloss_supervised_1: 0.244228, loss_supervised_2: 0.324678\n",
      "Train Epoch: 1 [8960/60000 (15%)]\tloss_supervised_1: 0.118846, loss_supervised_2: 0.176858\n",
      "Train Epoch: 1 [9600/60000 (16%)]\tloss_supervised_1: 0.317860, loss_supervised_2: 0.285997\n",
      "Train Epoch: 1 [10240/60000 (17%)]\tloss_supervised_1: 0.070200, loss_supervised_2: 0.124969\n",
      "Train Epoch: 1 [10880/60000 (18%)]\tloss_supervised_1: 0.305157, loss_supervised_2: 0.367358\n",
      "Train Epoch: 1 [11520/60000 (19%)]\tloss_supervised_1: 0.179549, loss_supervised_2: 0.174905\n",
      "Train Epoch: 1 [12160/60000 (20%)]\tloss_supervised_1: 0.241448, loss_supervised_2: 0.287798\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tloss_supervised_1: 0.190585, loss_supervised_2: 0.280333\n",
      "Train Epoch: 1 [13440/60000 (22%)]\tloss_supervised_1: 0.257337, loss_supervised_2: 0.255220\n",
      "Train Epoch: 1 [14080/60000 (23%)]\tloss_supervised_1: 0.180508, loss_supervised_2: 0.199335\n",
      "Train Epoch: 1 [14720/60000 (25%)]\tloss_supervised_1: 0.115888, loss_supervised_2: 0.117732\n",
      "Train Epoch: 1 [15360/60000 (26%)]\tloss_supervised_1: 0.203214, loss_supervised_2: 0.212427\n",
      "Train Epoch: 1 [16000/60000 (27%)]\tloss_supervised_1: 0.165634, loss_supervised_2: 0.237846\n",
      "Train Epoch: 1 [16640/60000 (28%)]\tloss_supervised_1: 0.229747, loss_supervised_2: 0.193872\n",
      "Train Epoch: 1 [17280/60000 (29%)]\tloss_supervised_1: 0.166492, loss_supervised_2: 0.203573\n",
      "Train Epoch: 1 [17920/60000 (30%)]\tloss_supervised_1: 0.229100, loss_supervised_2: 0.240839\n",
      "Train Epoch: 1 [18560/60000 (31%)]\tloss_supervised_1: 0.106040, loss_supervised_2: 0.127122\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tloss_supervised_1: 0.175754, loss_supervised_2: 0.211866\n",
      "Train Epoch: 1 [19840/60000 (33%)]\tloss_supervised_1: 0.208097, loss_supervised_2: 0.216733\n",
      "Train Epoch: 1 [20480/60000 (34%)]\tloss_supervised_1: 0.197225, loss_supervised_2: 0.270529\n",
      "Train Epoch: 1 [21120/60000 (35%)]\tloss_supervised_1: 0.153207, loss_supervised_2: 0.161435\n",
      "Train Epoch: 1 [21760/60000 (36%)]\tloss_supervised_1: 0.136924, loss_supervised_2: 0.162000\n",
      "Train Epoch: 1 [22400/60000 (37%)]\tloss_supervised_1: 0.194512, loss_supervised_2: 0.165985\n",
      "Train Epoch: 1 [23040/60000 (38%)]\tloss_supervised_1: 0.127446, loss_supervised_2: 0.197379\n",
      "Train Epoch: 1 [23680/60000 (39%)]\tloss_supervised_1: 0.193623, loss_supervised_2: 0.218020\n",
      "Train Epoch: 1 [24320/60000 (41%)]\tloss_supervised_1: 0.061315, loss_supervised_2: 0.070435\n",
      "Train Epoch: 1 [24960/60000 (42%)]\tloss_supervised_1: 0.179933, loss_supervised_2: 0.208089\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tloss_supervised_1: 0.266276, loss_supervised_2: 0.343371\n",
      "Train Epoch: 1 [26240/60000 (44%)]\tloss_supervised_1: 0.338155, loss_supervised_2: 0.420602\n",
      "Train Epoch: 1 [26880/60000 (45%)]\tloss_supervised_1: 0.034743, loss_supervised_2: 0.049566\n",
      "Train Epoch: 1 [27520/60000 (46%)]\tloss_supervised_1: 0.076865, loss_supervised_2: 0.077528\n",
      "Train Epoch: 1 [28160/60000 (47%)]\tloss_supervised_1: 0.104638, loss_supervised_2: 0.103249\n",
      "Train Epoch: 1 [28800/60000 (48%)]\tloss_supervised_1: 0.066514, loss_supervised_2: 0.067034\n",
      "Train Epoch: 1 [29440/60000 (49%)]\tloss_supervised_1: 0.125019, loss_supervised_2: 0.136328\n",
      "Train Epoch: 1 [30080/60000 (50%)]\tloss_supervised_1: 0.165122, loss_supervised_2: 0.182744\n",
      "Train Epoch: 1 [30720/60000 (51%)]\tloss_supervised_1: 0.089285, loss_supervised_2: 0.084623\n",
      "Train Epoch: 1 [31360/60000 (52%)]\tloss_supervised_1: 0.130613, loss_supervised_2: 0.151147\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tloss_supervised_1: 0.030056, loss_supervised_2: 0.021826\n",
      "Train Epoch: 1 [32640/60000 (54%)]\tloss_supervised_1: 0.074236, loss_supervised_2: 0.072091\n",
      "Train Epoch: 1 [33280/60000 (55%)]\tloss_supervised_1: 0.016222, loss_supervised_2: 0.012563\n",
      "Train Epoch: 1 [33920/60000 (57%)]\tloss_supervised_1: 0.064190, loss_supervised_2: 0.065228\n",
      "Train Epoch: 1 [34560/60000 (58%)]\tloss_supervised_1: 0.085544, loss_supervised_2: 0.087897\n",
      "Train Epoch: 1 [35200/60000 (59%)]\tloss_supervised_1: 0.030590, loss_supervised_2: 0.024528\n",
      "Train Epoch: 1 [35840/60000 (60%)]\tloss_supervised_1: 0.018451, loss_supervised_2: 0.015041\n",
      "Train Epoch: 1 [36480/60000 (61%)]\tloss_supervised_1: 0.118275, loss_supervised_2: 0.137569\n",
      "Train Epoch: 1 [37120/60000 (62%)]\tloss_supervised_1: 0.078040, loss_supervised_2: 0.085699\n",
      "Train Epoch: 1 [37760/60000 (63%)]\tloss_supervised_1: 0.083245, loss_supervised_2: 0.083584\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tloss_supervised_1: 0.072039, loss_supervised_2: 0.052737\n",
      "Train Epoch: 1 [39040/60000 (65%)]\tloss_supervised_1: 0.209748, loss_supervised_2: 0.195369\n",
      "Train Epoch: 1 [39680/60000 (66%)]\tloss_supervised_1: 0.042154, loss_supervised_2: 0.052268\n",
      "Train Epoch: 1 [40320/60000 (67%)]\tloss_supervised_1: 0.072353, loss_supervised_2: 0.056698\n",
      "Train Epoch: 1 [40960/60000 (68%)]\tloss_supervised_1: 0.073806, loss_supervised_2: 0.086368\n",
      "Train Epoch: 1 [41600/60000 (69%)]\tloss_supervised_1: 0.099220, loss_supervised_2: 0.080228\n",
      "Train Epoch: 1 [42240/60000 (70%)]\tloss_supervised_1: 0.034362, loss_supervised_2: 0.027026\n",
      "Train Epoch: 1 [42880/60000 (71%)]\tloss_supervised_1: 0.060518, loss_supervised_2: 0.046883\n",
      "Train Epoch: 1 [43520/60000 (72%)]\tloss_supervised_1: 0.034717, loss_supervised_2: 0.043482\n",
      "Train Epoch: 1 [44160/60000 (74%)]\tloss_supervised_1: 0.033284, loss_supervised_2: 0.020902\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tloss_supervised_1: 0.080951, loss_supervised_2: 0.057968\n",
      "Train Epoch: 1 [45440/60000 (76%)]\tloss_supervised_1: 0.029802, loss_supervised_2: 0.026850\n",
      "Train Epoch: 1 [46080/60000 (77%)]\tloss_supervised_1: 0.200351, loss_supervised_2: 0.194212\n",
      "Train Epoch: 1 [46720/60000 (78%)]\tloss_supervised_1: 0.059349, loss_supervised_2: 0.044841\n",
      "Train Epoch: 1 [47360/60000 (79%)]\tloss_supervised_1: 0.049745, loss_supervised_2: 0.046911\n",
      "Train Epoch: 1 [48000/60000 (80%)]\tloss_supervised_1: 0.015706, loss_supervised_2: 0.019262\n",
      "Train Epoch: 1 [48640/60000 (81%)]\tloss_supervised_1: 0.028640, loss_supervised_2: 0.018539\n",
      "Train Epoch: 1 [49280/60000 (82%)]\tloss_supervised_1: 0.241549, loss_supervised_2: 0.274154\n",
      "Train Epoch: 1 [49920/60000 (83%)]\tloss_supervised_1: 0.055673, loss_supervised_2: 0.053464\n",
      "Train Epoch: 1 [50560/60000 (84%)]\tloss_supervised_1: 0.033024, loss_supervised_2: 0.026858\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tloss_supervised_1: 0.218850, loss_supervised_2: 0.242546\n",
      "Train Epoch: 1 [51840/60000 (86%)]\tloss_supervised_1: 0.012649, loss_supervised_2: 0.007583\n",
      "Train Epoch: 1 [52480/60000 (87%)]\tloss_supervised_1: 0.017434, loss_supervised_2: 0.008136\n",
      "Train Epoch: 1 [53120/60000 (88%)]\tloss_supervised_1: 0.030042, loss_supervised_2: 0.040341\n",
      "Train Epoch: 1 [53760/60000 (90%)]\tloss_supervised_1: 0.080906, loss_supervised_2: 0.091398\n",
      "Train Epoch: 1 [54400/60000 (91%)]\tloss_supervised_1: 0.029272, loss_supervised_2: 0.019107\n",
      "Train Epoch: 1 [55040/60000 (92%)]\tloss_supervised_1: 0.062831, loss_supervised_2: 0.053432\n",
      "Train Epoch: 1 [55680/60000 (93%)]\tloss_supervised_1: 0.078620, loss_supervised_2: 0.134986\n",
      "Train Epoch: 1 [56320/60000 (94%)]\tloss_supervised_1: 0.103713, loss_supervised_2: 0.127716\n",
      "Train Epoch: 1 [56960/60000 (95%)]\tloss_supervised_1: 0.013552, loss_supervised_2: 0.005097\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tloss_supervised_1: 0.035578, loss_supervised_2: 0.020164\n",
      "Train Epoch: 1 [58240/60000 (97%)]\tloss_supervised_1: 0.009252, loss_supervised_2: 0.003958\n",
      "Train Epoch: 1 [58880/60000 (98%)]\tloss_supervised_1: 0.059601, loss_supervised_2: 0.054997\n",
      "Train Epoch: 1 [59520/60000 (99%)]\tloss_supervised_1: 0.075486, loss_supervised_2: 0.097531\n",
      "Train Epoch: 2 [0/60000 (0%)]\tloss_supervised_1: 0.054777, loss_supervised_2: 0.061457\n",
      "Train Epoch: 2 [640/60000 (1%)]\tloss_supervised_1: 0.085010, loss_supervised_2: 0.126800\n",
      "Train Epoch: 2 [1280/60000 (2%)]\tloss_supervised_1: 0.203490, loss_supervised_2: 0.197217\n",
      "Train Epoch: 2 [1920/60000 (3%)]\tloss_supervised_1: 0.043679, loss_supervised_2: 0.048517\n",
      "Train Epoch: 2 [2560/60000 (4%)]\tloss_supervised_1: 0.004746, loss_supervised_2: 0.002434\n",
      "Train Epoch: 2 [3200/60000 (5%)]\tloss_supervised_1: 0.101942, loss_supervised_2: 0.099046\n",
      "Train Epoch: 2 [3840/60000 (6%)]\tloss_supervised_1: 0.018516, loss_supervised_2: 0.018993\n",
      "Train Epoch: 2 [4480/60000 (7%)]\tloss_supervised_1: 0.031827, loss_supervised_2: 0.012958\n",
      "Train Epoch: 2 [5120/60000 (9%)]\tloss_supervised_1: 0.054849, loss_supervised_2: 0.059017\n",
      "Train Epoch: 2 [5760/60000 (10%)]\tloss_supervised_1: 0.007288, loss_supervised_2: 0.003672\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tloss_supervised_1: 0.037712, loss_supervised_2: 0.023438\n",
      "Train Epoch: 2 [7040/60000 (12%)]\tloss_supervised_1: 0.023347, loss_supervised_2: 0.011549\n",
      "Train Epoch: 2 [7680/60000 (13%)]\tloss_supervised_1: 0.060814, loss_supervised_2: 0.071721\n",
      "Train Epoch: 2 [8320/60000 (14%)]\tloss_supervised_1: 0.099552, loss_supervised_2: 0.098144\n",
      "Train Epoch: 2 [8960/60000 (15%)]\tloss_supervised_1: 0.020937, loss_supervised_2: 0.011485\n",
      "Train Epoch: 2 [9600/60000 (16%)]\tloss_supervised_1: 0.012520, loss_supervised_2: 0.005121\n",
      "Train Epoch: 2 [10240/60000 (17%)]\tloss_supervised_1: 0.057042, loss_supervised_2: 0.064402\n",
      "Train Epoch: 2 [10880/60000 (18%)]\tloss_supervised_1: 0.145198, loss_supervised_2: 0.131755\n",
      "Train Epoch: 2 [11520/60000 (19%)]\tloss_supervised_1: 0.011142, loss_supervised_2: 0.004874\n",
      "Train Epoch: 2 [12160/60000 (20%)]\tloss_supervised_1: 0.010351, loss_supervised_2: 0.006881\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tloss_supervised_1: 0.005198, loss_supervised_2: 0.001831\n",
      "Train Epoch: 2 [13440/60000 (22%)]\tloss_supervised_1: 0.020638, loss_supervised_2: 0.008418\n",
      "Train Epoch: 2 [14080/60000 (23%)]\tloss_supervised_1: 0.036546, loss_supervised_2: 0.045780\n",
      "Train Epoch: 2 [14720/60000 (25%)]\tloss_supervised_1: 0.036458, loss_supervised_2: 0.022330\n",
      "Train Epoch: 2 [15360/60000 (26%)]\tloss_supervised_1: 0.005639, loss_supervised_2: 0.002092\n",
      "Train Epoch: 2 [16000/60000 (27%)]\tloss_supervised_1: 0.128579, loss_supervised_2: 0.202047\n",
      "Train Epoch: 2 [16640/60000 (28%)]\tloss_supervised_1: 0.015507, loss_supervised_2: 0.008277\n",
      "Train Epoch: 2 [17280/60000 (29%)]\tloss_supervised_1: 0.085054, loss_supervised_2: 0.069115\n",
      "Train Epoch: 2 [17920/60000 (30%)]\tloss_supervised_1: 0.078294, loss_supervised_2: 0.096683\n",
      "Train Epoch: 2 [18560/60000 (31%)]\tloss_supervised_1: 0.021781, loss_supervised_2: 0.010855\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tloss_supervised_1: 0.047261, loss_supervised_2: 0.049199\n",
      "Train Epoch: 2 [19840/60000 (33%)]\tloss_supervised_1: 0.016666, loss_supervised_2: 0.003830\n",
      "Train Epoch: 2 [20480/60000 (34%)]\tloss_supervised_1: 0.011549, loss_supervised_2: 0.004434\n",
      "Train Epoch: 2 [21120/60000 (35%)]\tloss_supervised_1: 0.020046, loss_supervised_2: 0.005969\n",
      "Train Epoch: 2 [21760/60000 (36%)]\tloss_supervised_1: 0.062281, loss_supervised_2: 0.084673\n",
      "Train Epoch: 2 [22400/60000 (37%)]\tloss_supervised_1: 0.013885, loss_supervised_2: 0.019780\n",
      "Train Epoch: 2 [23040/60000 (38%)]\tloss_supervised_1: 0.128979, loss_supervised_2: 0.128714\n",
      "Train Epoch: 2 [23680/60000 (39%)]\tloss_supervised_1: 0.011454, loss_supervised_2: 0.005141\n",
      "Train Epoch: 2 [24320/60000 (41%)]\tloss_supervised_1: 0.006892, loss_supervised_2: 0.002793\n",
      "Train Epoch: 2 [24960/60000 (42%)]\tloss_supervised_1: 0.027577, loss_supervised_2: 0.010344\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tloss_supervised_1: 0.074679, loss_supervised_2: 0.094268\n",
      "Train Epoch: 2 [26240/60000 (44%)]\tloss_supervised_1: 0.044352, loss_supervised_2: 0.038341\n",
      "Train Epoch: 2 [26880/60000 (45%)]\tloss_supervised_1: 0.017404, loss_supervised_2: 0.013107\n",
      "Train Epoch: 2 [27520/60000 (46%)]\tloss_supervised_1: 0.049057, loss_supervised_2: 0.036417\n",
      "Train Epoch: 2 [28160/60000 (47%)]\tloss_supervised_1: 0.009404, loss_supervised_2: 0.003431\n",
      "Train Epoch: 2 [28800/60000 (48%)]\tloss_supervised_1: 0.021986, loss_supervised_2: 0.024803\n",
      "Train Epoch: 2 [29440/60000 (49%)]\tloss_supervised_1: 0.005051, loss_supervised_2: 0.001630\n",
      "Train Epoch: 2 [30080/60000 (50%)]\tloss_supervised_1: 0.005160, loss_supervised_2: 0.001426\n",
      "Train Epoch: 2 [30720/60000 (51%)]\tloss_supervised_1: 0.032216, loss_supervised_2: 0.031303\n",
      "Train Epoch: 2 [31360/60000 (52%)]\tloss_supervised_1: 0.014702, loss_supervised_2: 0.010571\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tloss_supervised_1: 0.013590, loss_supervised_2: 0.005369\n",
      "Train Epoch: 2 [32640/60000 (54%)]\tloss_supervised_1: 0.027083, loss_supervised_2: 0.028373\n",
      "Train Epoch: 2 [33280/60000 (55%)]\tloss_supervised_1: 0.026307, loss_supervised_2: 0.022367\n",
      "Train Epoch: 2 [33920/60000 (57%)]\tloss_supervised_1: 0.112993, loss_supervised_2: 0.102664\n",
      "Train Epoch: 2 [34560/60000 (58%)]\tloss_supervised_1: 0.012466, loss_supervised_2: 0.005634\n",
      "Train Epoch: 2 [35200/60000 (59%)]\tloss_supervised_1: 0.006504, loss_supervised_2: 0.001572\n",
      "Train Epoch: 2 [35840/60000 (60%)]\tloss_supervised_1: 0.046139, loss_supervised_2: 0.043908\n",
      "Train Epoch: 2 [36480/60000 (61%)]\tloss_supervised_1: 0.005488, loss_supervised_2: 0.001864\n",
      "Train Epoch: 2 [37120/60000 (62%)]\tloss_supervised_1: 0.004529, loss_supervised_2: 0.003612\n",
      "Train Epoch: 2 [37760/60000 (63%)]\tloss_supervised_1: 0.003846, loss_supervised_2: 0.001180\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tloss_supervised_1: 0.169505, loss_supervised_2: 0.202191\n",
      "Train Epoch: 2 [39040/60000 (65%)]\tloss_supervised_1: 0.079454, loss_supervised_2: 0.129779\n",
      "Train Epoch: 2 [39680/60000 (66%)]\tloss_supervised_1: 0.024737, loss_supervised_2: 0.027407\n",
      "Train Epoch: 2 [40320/60000 (67%)]\tloss_supervised_1: 0.005589, loss_supervised_2: 0.001968\n",
      "Train Epoch: 2 [40960/60000 (68%)]\tloss_supervised_1: 0.016651, loss_supervised_2: 0.013119\n",
      "Train Epoch: 2 [41600/60000 (69%)]\tloss_supervised_1: 0.082967, loss_supervised_2: 0.063084\n",
      "Train Epoch: 2 [42240/60000 (70%)]\tloss_supervised_1: 0.015686, loss_supervised_2: 0.021476\n",
      "Train Epoch: 2 [42880/60000 (71%)]\tloss_supervised_1: 0.065974, loss_supervised_2: 0.070354\n",
      "Train Epoch: 2 [43520/60000 (72%)]\tloss_supervised_1: 0.011161, loss_supervised_2: 0.006416\n",
      "Train Epoch: 2 [44160/60000 (74%)]\tloss_supervised_1: 0.007010, loss_supervised_2: 0.002261\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tloss_supervised_1: 0.025178, loss_supervised_2: 0.053586\n",
      "Train Epoch: 2 [45440/60000 (76%)]\tloss_supervised_1: 0.018445, loss_supervised_2: 0.025851\n",
      "Train Epoch: 2 [46080/60000 (77%)]\tloss_supervised_1: 0.012160, loss_supervised_2: 0.008613\n",
      "Train Epoch: 2 [46720/60000 (78%)]\tloss_supervised_1: 0.005059, loss_supervised_2: 0.002887\n",
      "Train Epoch: 2 [47360/60000 (79%)]\tloss_supervised_1: 0.010355, loss_supervised_2: 0.003649\n",
      "Train Epoch: 2 [48000/60000 (80%)]\tloss_supervised_1: 0.085204, loss_supervised_2: 0.110021\n",
      "Train Epoch: 2 [48640/60000 (81%)]\tloss_supervised_1: 0.031600, loss_supervised_2: 0.024002\n",
      "Train Epoch: 2 [49280/60000 (82%)]\tloss_supervised_1: 0.005232, loss_supervised_2: 0.004203\n",
      "Train Epoch: 2 [49920/60000 (83%)]\tloss_supervised_1: 0.012904, loss_supervised_2: 0.003880\n",
      "Train Epoch: 2 [50560/60000 (84%)]\tloss_supervised_1: 0.054984, loss_supervised_2: 0.089971\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tloss_supervised_1: 0.019806, loss_supervised_2: 0.008709\n",
      "Train Epoch: 2 [51840/60000 (86%)]\tloss_supervised_1: 0.032239, loss_supervised_2: 0.036316\n",
      "Train Epoch: 2 [52480/60000 (87%)]\tloss_supervised_1: 0.008246, loss_supervised_2: 0.002483\n",
      "Train Epoch: 2 [53120/60000 (88%)]\tloss_supervised_1: 0.019149, loss_supervised_2: 0.017803\n",
      "Train Epoch: 2 [53760/60000 (90%)]\tloss_supervised_1: 0.016510, loss_supervised_2: 0.006461\n",
      "Train Epoch: 2 [54400/60000 (91%)]\tloss_supervised_1: 0.008618, loss_supervised_2: 0.003174\n",
      "Train Epoch: 2 [55040/60000 (92%)]\tloss_supervised_1: 0.012790, loss_supervised_2: 0.003110\n",
      "Train Epoch: 2 [55680/60000 (93%)]\tloss_supervised_1: 0.037778, loss_supervised_2: 0.025794\n",
      "Train Epoch: 2 [56320/60000 (94%)]\tloss_supervised_1: 0.003753, loss_supervised_2: 0.001383\n",
      "Train Epoch: 2 [56960/60000 (95%)]\tloss_supervised_1: 0.105307, loss_supervised_2: 0.115563\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tloss_supervised_1: 0.006334, loss_supervised_2: 0.003174\n",
      "Train Epoch: 2 [58240/60000 (97%)]\tloss_supervised_1: 0.048605, loss_supervised_2: 0.047280\n",
      "Train Epoch: 2 [58880/60000 (98%)]\tloss_supervised_1: 0.013104, loss_supervised_2: 0.010545\n",
      "Train Epoch: 2 [59520/60000 (99%)]\tloss_supervised_1: 0.069877, loss_supervised_2: 0.045082\n",
      "Train Epoch: 3 [0/60000 (0%)]\tloss_supervised_1: 0.113195, loss_supervised_2: 0.101110\n",
      "Train Epoch: 3 [640/60000 (1%)]\tloss_supervised_1: 0.010379, loss_supervised_2: 0.008704\n",
      "Train Epoch: 3 [1280/60000 (2%)]\tloss_supervised_1: 0.072719, loss_supervised_2: 0.085943\n",
      "Train Epoch: 3 [1920/60000 (3%)]\tloss_supervised_1: 0.122387, loss_supervised_2: 0.164961\n",
      "Train Epoch: 3 [2560/60000 (4%)]\tloss_supervised_1: 0.008956, loss_supervised_2: 0.004020\n",
      "Train Epoch: 3 [3200/60000 (5%)]\tloss_supervised_1: 0.009063, loss_supervised_2: 0.006959\n",
      "Train Epoch: 3 [3840/60000 (6%)]\tloss_supervised_1: 0.011051, loss_supervised_2: 0.006432\n",
      "Train Epoch: 3 [4480/60000 (7%)]\tloss_supervised_1: 0.031117, loss_supervised_2: 0.031744\n",
      "Train Epoch: 3 [5120/60000 (9%)]\tloss_supervised_1: 0.012536, loss_supervised_2: 0.017003\n",
      "Train Epoch: 3 [5760/60000 (10%)]\tloss_supervised_1: 0.076466, loss_supervised_2: 0.088861\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tloss_supervised_1: 0.003663, loss_supervised_2: 0.001302\n",
      "Train Epoch: 3 [7040/60000 (12%)]\tloss_supervised_1: 0.009700, loss_supervised_2: 0.003843\n",
      "Train Epoch: 3 [7680/60000 (13%)]\tloss_supervised_1: 0.001109, loss_supervised_2: 0.000590\n",
      "Train Epoch: 3 [8320/60000 (14%)]\tloss_supervised_1: 0.013954, loss_supervised_2: 0.012599\n",
      "Train Epoch: 3 [8960/60000 (15%)]\tloss_supervised_1: 0.005057, loss_supervised_2: 0.001992\n",
      "Train Epoch: 3 [9600/60000 (16%)]\tloss_supervised_1: 0.012071, loss_supervised_2: 0.010188\n",
      "Train Epoch: 3 [10240/60000 (17%)]\tloss_supervised_1: 0.042820, loss_supervised_2: 0.057951\n",
      "Train Epoch: 3 [10880/60000 (18%)]\tloss_supervised_1: 0.024126, loss_supervised_2: 0.031171\n",
      "Train Epoch: 3 [11520/60000 (19%)]\tloss_supervised_1: 0.005963, loss_supervised_2: 0.002641\n",
      "Train Epoch: 3 [12160/60000 (20%)]\tloss_supervised_1: 0.047791, loss_supervised_2: 0.031324\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tloss_supervised_1: 0.055103, loss_supervised_2: 0.051547\n",
      "Train Epoch: 3 [13440/60000 (22%)]\tloss_supervised_1: 0.004154, loss_supervised_2: 0.000868\n",
      "Train Epoch: 3 [14080/60000 (23%)]\tloss_supervised_1: 0.012098, loss_supervised_2: 0.006984\n",
      "Train Epoch: 3 [14720/60000 (25%)]\tloss_supervised_1: 0.005564, loss_supervised_2: 0.002666\n",
      "Train Epoch: 3 [15360/60000 (26%)]\tloss_supervised_1: 0.032433, loss_supervised_2: 0.033833\n",
      "Train Epoch: 3 [16000/60000 (27%)]\tloss_supervised_1: 0.006908, loss_supervised_2: 0.003669\n",
      "Train Epoch: 3 [16640/60000 (28%)]\tloss_supervised_1: 0.009707, loss_supervised_2: 0.005038\n",
      "Train Epoch: 3 [17280/60000 (29%)]\tloss_supervised_1: 0.070026, loss_supervised_2: 0.059761\n",
      "Train Epoch: 3 [17920/60000 (30%)]\tloss_supervised_1: 0.013651, loss_supervised_2: 0.009457\n",
      "Train Epoch: 3 [18560/60000 (31%)]\tloss_supervised_1: 0.006759, loss_supervised_2: 0.004514\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tloss_supervised_1: 0.152109, loss_supervised_2: 0.170503\n",
      "Train Epoch: 3 [19840/60000 (33%)]\tloss_supervised_1: 0.022715, loss_supervised_2: 0.022401\n",
      "Train Epoch: 3 [20480/60000 (34%)]\tloss_supervised_1: 0.007351, loss_supervised_2: 0.004846\n",
      "Train Epoch: 3 [21120/60000 (35%)]\tloss_supervised_1: 0.001240, loss_supervised_2: 0.000489\n",
      "Train Epoch: 3 [21760/60000 (36%)]\tloss_supervised_1: 0.001489, loss_supervised_2: 0.000643\n",
      "Train Epoch: 3 [22400/60000 (37%)]\tloss_supervised_1: 0.004776, loss_supervised_2: 0.001254\n",
      "Train Epoch: 3 [23040/60000 (38%)]\tloss_supervised_1: 0.002397, loss_supervised_2: 0.000969\n",
      "Train Epoch: 3 [23680/60000 (39%)]\tloss_supervised_1: 0.008061, loss_supervised_2: 0.002762\n",
      "Train Epoch: 3 [24320/60000 (41%)]\tloss_supervised_1: 0.003944, loss_supervised_2: 0.001332\n",
      "Train Epoch: 3 [24960/60000 (42%)]\tloss_supervised_1: 0.024133, loss_supervised_2: 0.018499\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tloss_supervised_1: 0.041075, loss_supervised_2: 0.026793\n",
      "Train Epoch: 3 [26240/60000 (44%)]\tloss_supervised_1: 0.031997, loss_supervised_2: 0.047027\n",
      "Train Epoch: 3 [26880/60000 (45%)]\tloss_supervised_1: 0.145159, loss_supervised_2: 0.145826\n",
      "Train Epoch: 3 [27520/60000 (46%)]\tloss_supervised_1: 0.001489, loss_supervised_2: 0.000996\n",
      "Train Epoch: 3 [28160/60000 (47%)]\tloss_supervised_1: 0.005254, loss_supervised_2: 0.003428\n",
      "Train Epoch: 3 [28800/60000 (48%)]\tloss_supervised_1: 0.015938, loss_supervised_2: 0.017174\n",
      "Train Epoch: 3 [29440/60000 (49%)]\tloss_supervised_1: 0.013067, loss_supervised_2: 0.021883\n",
      "Train Epoch: 3 [30080/60000 (50%)]\tloss_supervised_1: 0.033807, loss_supervised_2: 0.063382\n",
      "Train Epoch: 3 [30720/60000 (51%)]\tloss_supervised_1: 0.024038, loss_supervised_2: 0.014551\n",
      "Train Epoch: 3 [31360/60000 (52%)]\tloss_supervised_1: 0.022034, loss_supervised_2: 0.016567\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tloss_supervised_1: 0.103658, loss_supervised_2: 0.117345\n",
      "Train Epoch: 3 [32640/60000 (54%)]\tloss_supervised_1: 0.005908, loss_supervised_2: 0.002159\n",
      "Train Epoch: 3 [33280/60000 (55%)]\tloss_supervised_1: 0.069060, loss_supervised_2: 0.077698\n",
      "Train Epoch: 3 [33920/60000 (57%)]\tloss_supervised_1: 0.010174, loss_supervised_2: 0.006498\n",
      "Train Epoch: 3 [34560/60000 (58%)]\tloss_supervised_1: 0.003855, loss_supervised_2: 0.002212\n",
      "Train Epoch: 3 [35200/60000 (59%)]\tloss_supervised_1: 0.002122, loss_supervised_2: 0.001076\n",
      "Train Epoch: 3 [35840/60000 (60%)]\tloss_supervised_1: 0.001741, loss_supervised_2: 0.000821\n",
      "Train Epoch: 3 [36480/60000 (61%)]\tloss_supervised_1: 0.117347, loss_supervised_2: 0.123063\n",
      "Train Epoch: 3 [37120/60000 (62%)]\tloss_supervised_1: 0.235729, loss_supervised_2: 0.312421\n",
      "Train Epoch: 3 [37760/60000 (63%)]\tloss_supervised_1: 0.070728, loss_supervised_2: 0.079090\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tloss_supervised_1: 0.020278, loss_supervised_2: 0.022461\n",
      "Train Epoch: 3 [39040/60000 (65%)]\tloss_supervised_1: 0.043240, loss_supervised_2: 0.069414\n",
      "Train Epoch: 3 [39680/60000 (66%)]\tloss_supervised_1: 0.013351, loss_supervised_2: 0.005349\n",
      "Train Epoch: 3 [40320/60000 (67%)]\tloss_supervised_1: 0.033786, loss_supervised_2: 0.027238\n",
      "Train Epoch: 3 [40960/60000 (68%)]\tloss_supervised_1: 0.011834, loss_supervised_2: 0.003337\n",
      "Train Epoch: 3 [41600/60000 (69%)]\tloss_supervised_1: 0.005367, loss_supervised_2: 0.001600\n",
      "Train Epoch: 3 [42240/60000 (70%)]\tloss_supervised_1: 0.002585, loss_supervised_2: 0.002072\n",
      "Train Epoch: 3 [42880/60000 (71%)]\tloss_supervised_1: 0.005922, loss_supervised_2: 0.003908\n",
      "Train Epoch: 3 [43520/60000 (72%)]\tloss_supervised_1: 0.004408, loss_supervised_2: 0.002433\n",
      "Train Epoch: 3 [44160/60000 (74%)]\tloss_supervised_1: 0.110956, loss_supervised_2: 0.180223\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tloss_supervised_1: 0.010210, loss_supervised_2: 0.006433\n",
      "Train Epoch: 3 [45440/60000 (76%)]\tloss_supervised_1: 0.006818, loss_supervised_2: 0.007396\n",
      "Train Epoch: 3 [46080/60000 (77%)]\tloss_supervised_1: 0.009826, loss_supervised_2: 0.034283\n",
      "Train Epoch: 3 [46720/60000 (78%)]\tloss_supervised_1: 0.030667, loss_supervised_2: 0.023471\n",
      "Train Epoch: 3 [47360/60000 (79%)]\tloss_supervised_1: 0.008999, loss_supervised_2: 0.007941\n",
      "Train Epoch: 3 [48000/60000 (80%)]\tloss_supervised_1: 0.008258, loss_supervised_2: 0.005146\n",
      "Train Epoch: 3 [48640/60000 (81%)]\tloss_supervised_1: 0.010529, loss_supervised_2: 0.007707\n",
      "Train Epoch: 3 [49280/60000 (82%)]\tloss_supervised_1: 0.008421, loss_supervised_2: 0.004594\n",
      "Train Epoch: 3 [49920/60000 (83%)]\tloss_supervised_1: 0.001419, loss_supervised_2: 0.000864\n",
      "Train Epoch: 3 [50560/60000 (84%)]\tloss_supervised_1: 0.004153, loss_supervised_2: 0.001636\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tloss_supervised_1: 0.008578, loss_supervised_2: 0.001571\n",
      "Train Epoch: 3 [51840/60000 (86%)]\tloss_supervised_1: 0.108577, loss_supervised_2: 0.160600\n",
      "Train Epoch: 3 [52480/60000 (87%)]\tloss_supervised_1: 0.065793, loss_supervised_2: 0.094943\n",
      "Train Epoch: 3 [53120/60000 (88%)]\tloss_supervised_1: 0.019815, loss_supervised_2: 0.015758\n",
      "Train Epoch: 3 [53760/60000 (90%)]\tloss_supervised_1: 0.005713, loss_supervised_2: 0.001607\n",
      "Train Epoch: 3 [54400/60000 (91%)]\tloss_supervised_1: 0.004662, loss_supervised_2: 0.002556\n",
      "Train Epoch: 3 [55040/60000 (92%)]\tloss_supervised_1: 0.000655, loss_supervised_2: 0.000478\n",
      "Train Epoch: 3 [55680/60000 (93%)]\tloss_supervised_1: 0.076706, loss_supervised_2: 0.089092\n",
      "Train Epoch: 3 [56320/60000 (94%)]\tloss_supervised_1: 0.077170, loss_supervised_2: 0.094466\n",
      "Train Epoch: 3 [56960/60000 (95%)]\tloss_supervised_1: 0.004127, loss_supervised_2: 0.001643\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tloss_supervised_1: 0.004600, loss_supervised_2: 0.003573\n",
      "Train Epoch: 3 [58240/60000 (97%)]\tloss_supervised_1: 0.003472, loss_supervised_2: 0.002312\n",
      "Train Epoch: 3 [58880/60000 (98%)]\tloss_supervised_1: 0.005737, loss_supervised_2: 0.001843\n",
      "Train Epoch: 3 [59520/60000 (99%)]\tloss_supervised_1: 0.033360, loss_supervised_2: 0.040556\n",
      "Train Epoch: 4 [0/60000 (0%)]\tloss_supervised_1: 0.003809, loss_supervised_2: 0.001918\n",
      "Train Epoch: 4 [640/60000 (1%)]\tloss_supervised_1: 0.118145, loss_supervised_2: 0.179923\n",
      "Train Epoch: 4 [1280/60000 (2%)]\tloss_supervised_1: 0.000996, loss_supervised_2: 0.000645\n",
      "Train Epoch: 4 [1920/60000 (3%)]\tloss_supervised_1: 0.005814, loss_supervised_2: 0.008431\n",
      "Train Epoch: 4 [2560/60000 (4%)]\tloss_supervised_1: 0.002089, loss_supervised_2: 0.001928\n",
      "Train Epoch: 4 [3200/60000 (5%)]\tloss_supervised_1: 0.000691, loss_supervised_2: 0.000731\n",
      "Train Epoch: 4 [3840/60000 (6%)]\tloss_supervised_1: 0.006035, loss_supervised_2: 0.003332\n",
      "Train Epoch: 4 [4480/60000 (7%)]\tloss_supervised_1: 0.007514, loss_supervised_2: 0.012604\n",
      "Train Epoch: 4 [5120/60000 (9%)]\tloss_supervised_1: 0.061846, loss_supervised_2: 0.068902\n",
      "Train Epoch: 4 [5760/60000 (10%)]\tloss_supervised_1: 0.004274, loss_supervised_2: 0.001655\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tloss_supervised_1: 0.004767, loss_supervised_2: 0.003979\n",
      "Train Epoch: 4 [7040/60000 (12%)]\tloss_supervised_1: 0.004520, loss_supervised_2: 0.002048\n",
      "Train Epoch: 4 [7680/60000 (13%)]\tloss_supervised_1: 0.006447, loss_supervised_2: 0.005411\n",
      "Train Epoch: 4 [8320/60000 (14%)]\tloss_supervised_1: 0.027937, loss_supervised_2: 0.016300\n",
      "Train Epoch: 4 [8960/60000 (15%)]\tloss_supervised_1: 0.011281, loss_supervised_2: 0.009312\n",
      "Train Epoch: 4 [9600/60000 (16%)]\tloss_supervised_1: 0.046835, loss_supervised_2: 0.083623\n",
      "Train Epoch: 4 [10240/60000 (17%)]\tloss_supervised_1: 0.002962, loss_supervised_2: 0.000947\n",
      "Train Epoch: 4 [10880/60000 (18%)]\tloss_supervised_1: 0.083588, loss_supervised_2: 0.085511\n",
      "Train Epoch: 4 [11520/60000 (19%)]\tloss_supervised_1: 0.025805, loss_supervised_2: 0.019672\n",
      "Train Epoch: 4 [12160/60000 (20%)]\tloss_supervised_1: 0.022422, loss_supervised_2: 0.033487\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tloss_supervised_1: 0.001785, loss_supervised_2: 0.001238\n",
      "Train Epoch: 4 [13440/60000 (22%)]\tloss_supervised_1: 0.012836, loss_supervised_2: 0.004658\n",
      "Train Epoch: 4 [14080/60000 (23%)]\tloss_supervised_1: 0.099019, loss_supervised_2: 0.113913\n",
      "Train Epoch: 4 [14720/60000 (25%)]\tloss_supervised_1: 0.002047, loss_supervised_2: 0.001762\n",
      "Train Epoch: 4 [15360/60000 (26%)]\tloss_supervised_1: 0.034882, loss_supervised_2: 0.022659\n",
      "Train Epoch: 4 [16000/60000 (27%)]\tloss_supervised_1: 0.011219, loss_supervised_2: 0.043048\n",
      "Train Epoch: 4 [16640/60000 (28%)]\tloss_supervised_1: 0.024967, loss_supervised_2: 0.034235\n",
      "Train Epoch: 4 [17280/60000 (29%)]\tloss_supervised_1: 0.091991, loss_supervised_2: 0.124505\n",
      "Train Epoch: 4 [17920/60000 (30%)]\tloss_supervised_1: 0.005765, loss_supervised_2: 0.002864\n",
      "Train Epoch: 4 [18560/60000 (31%)]\tloss_supervised_1: 0.002444, loss_supervised_2: 0.001176\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tloss_supervised_1: 0.004055, loss_supervised_2: 0.006534\n",
      "Train Epoch: 4 [19840/60000 (33%)]\tloss_supervised_1: 0.047325, loss_supervised_2: 0.049911\n",
      "Train Epoch: 4 [20480/60000 (34%)]\tloss_supervised_1: 0.240536, loss_supervised_2: 0.335941\n",
      "Train Epoch: 4 [21120/60000 (35%)]\tloss_supervised_1: 0.042274, loss_supervised_2: 0.059786\n",
      "Train Epoch: 4 [21760/60000 (36%)]\tloss_supervised_1: 0.056283, loss_supervised_2: 0.063349\n",
      "Train Epoch: 4 [22400/60000 (37%)]\tloss_supervised_1: 0.044366, loss_supervised_2: 0.066115\n",
      "Train Epoch: 4 [23040/60000 (38%)]\tloss_supervised_1: 0.005949, loss_supervised_2: 0.003435\n",
      "Train Epoch: 4 [23680/60000 (39%)]\tloss_supervised_1: 0.019995, loss_supervised_2: 0.016713\n",
      "Train Epoch: 4 [24320/60000 (41%)]\tloss_supervised_1: 0.007008, loss_supervised_2: 0.003136\n",
      "Train Epoch: 4 [24960/60000 (42%)]\tloss_supervised_1: 0.001550, loss_supervised_2: 0.001695\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tloss_supervised_1: 0.065668, loss_supervised_2: 0.090977\n",
      "Train Epoch: 4 [26240/60000 (44%)]\tloss_supervised_1: 0.002871, loss_supervised_2: 0.002344\n",
      "Train Epoch: 4 [26880/60000 (45%)]\tloss_supervised_1: 0.005072, loss_supervised_2: 0.002181\n",
      "Train Epoch: 4 [27520/60000 (46%)]\tloss_supervised_1: 0.000662, loss_supervised_2: 0.000548\n",
      "Train Epoch: 4 [28160/60000 (47%)]\tloss_supervised_1: 0.009406, loss_supervised_2: 0.015782\n",
      "Train Epoch: 4 [28800/60000 (48%)]\tloss_supervised_1: 0.000389, loss_supervised_2: 0.000368\n",
      "Train Epoch: 4 [29440/60000 (49%)]\tloss_supervised_1: 0.001515, loss_supervised_2: 0.000990\n",
      "Train Epoch: 4 [30080/60000 (50%)]\tloss_supervised_1: 0.011988, loss_supervised_2: 0.007534\n",
      "Train Epoch: 4 [30720/60000 (51%)]\tloss_supervised_1: 0.055019, loss_supervised_2: 0.084963\n",
      "Train Epoch: 4 [31360/60000 (52%)]\tloss_supervised_1: 0.000819, loss_supervised_2: 0.000682\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tloss_supervised_1: 0.005103, loss_supervised_2: 0.002325\n",
      "Train Epoch: 4 [32640/60000 (54%)]\tloss_supervised_1: 0.002409, loss_supervised_2: 0.001624\n",
      "Train Epoch: 4 [33280/60000 (55%)]\tloss_supervised_1: 0.032162, loss_supervised_2: 0.036653\n",
      "Train Epoch: 4 [33920/60000 (57%)]\tloss_supervised_1: 0.001293, loss_supervised_2: 0.001581\n",
      "Train Epoch: 4 [34560/60000 (58%)]\tloss_supervised_1: 0.006032, loss_supervised_2: 0.003021\n",
      "Train Epoch: 4 [35200/60000 (59%)]\tloss_supervised_1: 0.000683, loss_supervised_2: 0.000302\n",
      "Train Epoch: 4 [35840/60000 (60%)]\tloss_supervised_1: 0.013569, loss_supervised_2: 0.022646\n",
      "Train Epoch: 4 [36480/60000 (61%)]\tloss_supervised_1: 0.084858, loss_supervised_2: 0.117724\n",
      "Train Epoch: 4 [37120/60000 (62%)]\tloss_supervised_1: 0.005060, loss_supervised_2: 0.001870\n",
      "Train Epoch: 4 [37760/60000 (63%)]\tloss_supervised_1: 0.128666, loss_supervised_2: 0.147964\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tloss_supervised_1: 0.008629, loss_supervised_2: 0.003227\n",
      "Train Epoch: 4 [39040/60000 (65%)]\tloss_supervised_1: 0.008498, loss_supervised_2: 0.005564\n",
      "Train Epoch: 4 [39680/60000 (66%)]\tloss_supervised_1: 0.075622, loss_supervised_2: 0.076428\n",
      "Train Epoch: 4 [40320/60000 (67%)]\tloss_supervised_1: 0.009180, loss_supervised_2: 0.011472\n",
      "Train Epoch: 4 [40960/60000 (68%)]\tloss_supervised_1: 0.004773, loss_supervised_2: 0.002629\n",
      "Train Epoch: 4 [41600/60000 (69%)]\tloss_supervised_1: 0.000474, loss_supervised_2: 0.000493\n",
      "Train Epoch: 4 [42240/60000 (70%)]\tloss_supervised_1: 0.023828, loss_supervised_2: 0.027689\n",
      "Train Epoch: 4 [42880/60000 (71%)]\tloss_supervised_1: 0.001261, loss_supervised_2: 0.000991\n",
      "Train Epoch: 4 [43520/60000 (72%)]\tloss_supervised_1: 0.066651, loss_supervised_2: 0.065353\n",
      "Train Epoch: 4 [44160/60000 (74%)]\tloss_supervised_1: 0.000411, loss_supervised_2: 0.000323\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tloss_supervised_1: 0.016835, loss_supervised_2: 0.013318\n",
      "Train Epoch: 4 [45440/60000 (76%)]\tloss_supervised_1: 0.000909, loss_supervised_2: 0.001551\n",
      "Train Epoch: 4 [46080/60000 (77%)]\tloss_supervised_1: 0.003392, loss_supervised_2: 0.001476\n",
      "Train Epoch: 4 [46720/60000 (78%)]\tloss_supervised_1: 0.003206, loss_supervised_2: 0.002459\n",
      "Train Epoch: 4 [47360/60000 (79%)]\tloss_supervised_1: 0.012453, loss_supervised_2: 0.020588\n",
      "Train Epoch: 4 [48000/60000 (80%)]\tloss_supervised_1: 0.069451, loss_supervised_2: 0.087071\n",
      "Train Epoch: 4 [48640/60000 (81%)]\tloss_supervised_1: 0.051595, loss_supervised_2: 0.070492\n",
      "Train Epoch: 4 [49280/60000 (82%)]\tloss_supervised_1: 0.005621, loss_supervised_2: 0.005187\n",
      "Train Epoch: 4 [49920/60000 (83%)]\tloss_supervised_1: 0.045578, loss_supervised_2: 0.077582\n",
      "Train Epoch: 4 [50560/60000 (84%)]\tloss_supervised_1: 0.002786, loss_supervised_2: 0.002924\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tloss_supervised_1: 0.002048, loss_supervised_2: 0.001628\n",
      "Train Epoch: 4 [51840/60000 (86%)]\tloss_supervised_1: 0.076958, loss_supervised_2: 0.075588\n",
      "Train Epoch: 4 [52480/60000 (87%)]\tloss_supervised_1: 0.021409, loss_supervised_2: 0.030341\n",
      "Train Epoch: 4 [53120/60000 (88%)]\tloss_supervised_1: 0.006336, loss_supervised_2: 0.005532\n",
      "Train Epoch: 4 [53760/60000 (90%)]\tloss_supervised_1: 0.063372, loss_supervised_2: 0.044456\n",
      "Train Epoch: 4 [54400/60000 (91%)]\tloss_supervised_1: 0.036499, loss_supervised_2: 0.042440\n",
      "Train Epoch: 4 [55040/60000 (92%)]\tloss_supervised_1: 0.001200, loss_supervised_2: 0.000756\n",
      "Train Epoch: 4 [55680/60000 (93%)]\tloss_supervised_1: 0.006887, loss_supervised_2: 0.018656\n",
      "Train Epoch: 4 [56320/60000 (94%)]\tloss_supervised_1: 0.003762, loss_supervised_2: 0.002052\n",
      "Train Epoch: 4 [56960/60000 (95%)]\tloss_supervised_1: 0.001364, loss_supervised_2: 0.000607\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tloss_supervised_1: 0.011831, loss_supervised_2: 0.022477\n",
      "Train Epoch: 4 [58240/60000 (97%)]\tloss_supervised_1: 0.031495, loss_supervised_2: 0.027168\n",
      "Train Epoch: 4 [58880/60000 (98%)]\tloss_supervised_1: 0.039270, loss_supervised_2: 0.028232\n",
      "Train Epoch: 4 [59520/60000 (99%)]\tloss_supervised_1: 0.004758, loss_supervised_2: 0.002123\n",
      "Train Epoch: 5 [0/60000 (0%)]\tloss_supervised_1: 0.028909, loss_supervised_2: 0.059815\n",
      "Train Epoch: 5 [640/60000 (1%)]\tloss_supervised_1: 0.004952, loss_supervised_2: 0.007717\n",
      "Train Epoch: 5 [1280/60000 (2%)]\tloss_supervised_1: 0.025436, loss_supervised_2: 0.014651\n",
      "Train Epoch: 5 [1920/60000 (3%)]\tloss_supervised_1: 0.001330, loss_supervised_2: 0.001359\n",
      "Train Epoch: 5 [2560/60000 (4%)]\tloss_supervised_1: 0.001158, loss_supervised_2: 0.001886\n",
      "Train Epoch: 5 [3200/60000 (5%)]\tloss_supervised_1: 0.035074, loss_supervised_2: 0.063783\n",
      "Train Epoch: 5 [3840/60000 (6%)]\tloss_supervised_1: 0.034672, loss_supervised_2: 0.055160\n",
      "Train Epoch: 5 [4480/60000 (7%)]\tloss_supervised_1: 0.056729, loss_supervised_2: 0.080116\n",
      "Train Epoch: 5 [5120/60000 (9%)]\tloss_supervised_1: 0.001385, loss_supervised_2: 0.001142\n",
      "Train Epoch: 5 [5760/60000 (10%)]\tloss_supervised_1: 0.001378, loss_supervised_2: 0.001321\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tloss_supervised_1: 0.005930, loss_supervised_2: 0.018143\n",
      "Train Epoch: 5 [7040/60000 (12%)]\tloss_supervised_1: 0.000306, loss_supervised_2: 0.000395\n",
      "Train Epoch: 5 [7680/60000 (13%)]\tloss_supervised_1: 0.005140, loss_supervised_2: 0.005474\n",
      "Train Epoch: 5 [8320/60000 (14%)]\tloss_supervised_1: 0.002673, loss_supervised_2: 0.001837\n",
      "Train Epoch: 5 [8960/60000 (15%)]\tloss_supervised_1: 0.204788, loss_supervised_2: 0.239994\n",
      "Train Epoch: 5 [9600/60000 (16%)]\tloss_supervised_1: 0.001147, loss_supervised_2: 0.000703\n",
      "Train Epoch: 5 [10240/60000 (17%)]\tloss_supervised_1: 0.006846, loss_supervised_2: 0.003620\n",
      "Train Epoch: 5 [10880/60000 (18%)]\tloss_supervised_1: 0.031031, loss_supervised_2: 0.038465\n",
      "Train Epoch: 5 [11520/60000 (19%)]\tloss_supervised_1: 0.004815, loss_supervised_2: 0.005477\n",
      "Train Epoch: 5 [12160/60000 (20%)]\tloss_supervised_1: 0.000622, loss_supervised_2: 0.001217\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tloss_supervised_1: 0.002816, loss_supervised_2: 0.004317\n",
      "Train Epoch: 5 [13440/60000 (22%)]\tloss_supervised_1: 0.093187, loss_supervised_2: 0.104971\n",
      "Train Epoch: 5 [14080/60000 (23%)]\tloss_supervised_1: 0.005559, loss_supervised_2: 0.002896\n",
      "Train Epoch: 5 [14720/60000 (25%)]\tloss_supervised_1: 0.010692, loss_supervised_2: 0.008755\n",
      "Train Epoch: 5 [15360/60000 (26%)]\tloss_supervised_1: 0.001909, loss_supervised_2: 0.001018\n",
      "Train Epoch: 5 [16000/60000 (27%)]\tloss_supervised_1: 0.001524, loss_supervised_2: 0.001268\n",
      "Train Epoch: 5 [16640/60000 (28%)]\tloss_supervised_1: 0.005702, loss_supervised_2: 0.004520\n",
      "Train Epoch: 5 [17280/60000 (29%)]\tloss_supervised_1: 0.050596, loss_supervised_2: 0.053167\n",
      "Train Epoch: 5 [17920/60000 (30%)]\tloss_supervised_1: 0.012134, loss_supervised_2: 0.018329\n",
      "Train Epoch: 5 [18560/60000 (31%)]\tloss_supervised_1: 0.024160, loss_supervised_2: 0.027184\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tloss_supervised_1: 0.011103, loss_supervised_2: 0.006398\n",
      "Train Epoch: 5 [19840/60000 (33%)]\tloss_supervised_1: 0.004113, loss_supervised_2: 0.001520\n",
      "Train Epoch: 5 [20480/60000 (34%)]\tloss_supervised_1: 0.022657, loss_supervised_2: 0.010233\n",
      "Train Epoch: 5 [21120/60000 (35%)]\tloss_supervised_1: 0.032626, loss_supervised_2: 0.051263\n",
      "Train Epoch: 5 [21760/60000 (36%)]\tloss_supervised_1: 0.008347, loss_supervised_2: 0.004112\n",
      "Train Epoch: 5 [22400/60000 (37%)]\tloss_supervised_1: 0.000621, loss_supervised_2: 0.000606\n",
      "Train Epoch: 5 [23040/60000 (38%)]\tloss_supervised_1: 0.001123, loss_supervised_2: 0.000857\n",
      "Train Epoch: 5 [23680/60000 (39%)]\tloss_supervised_1: 0.023013, loss_supervised_2: 0.013455\n",
      "Train Epoch: 5 [24320/60000 (41%)]\tloss_supervised_1: 0.088049, loss_supervised_2: 0.123782\n",
      "Train Epoch: 5 [24960/60000 (42%)]\tloss_supervised_1: 0.020414, loss_supervised_2: 0.042437\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tloss_supervised_1: 0.000458, loss_supervised_2: 0.000648\n",
      "Train Epoch: 5 [26240/60000 (44%)]\tloss_supervised_1: 0.079114, loss_supervised_2: 0.099095\n",
      "Train Epoch: 5 [26880/60000 (45%)]\tloss_supervised_1: 0.001542, loss_supervised_2: 0.001113\n",
      "Train Epoch: 5 [27520/60000 (46%)]\tloss_supervised_1: 0.055653, loss_supervised_2: 0.052403\n",
      "Train Epoch: 5 [28160/60000 (47%)]\tloss_supervised_1: 0.000938, loss_supervised_2: 0.000673\n",
      "Train Epoch: 5 [28800/60000 (48%)]\tloss_supervised_1: 0.000829, loss_supervised_2: 0.000418\n",
      "Train Epoch: 5 [29440/60000 (49%)]\tloss_supervised_1: 0.001009, loss_supervised_2: 0.000790\n",
      "Train Epoch: 5 [30080/60000 (50%)]\tloss_supervised_1: 0.007020, loss_supervised_2: 0.003849\n",
      "Train Epoch: 5 [30720/60000 (51%)]\tloss_supervised_1: 0.025565, loss_supervised_2: 0.025906\n",
      "Train Epoch: 5 [31360/60000 (52%)]\tloss_supervised_1: 0.001956, loss_supervised_2: 0.001002\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tloss_supervised_1: 0.075417, loss_supervised_2: 0.124482\n",
      "Train Epoch: 5 [32640/60000 (54%)]\tloss_supervised_1: 0.012434, loss_supervised_2: 0.019003\n",
      "Train Epoch: 5 [33280/60000 (55%)]\tloss_supervised_1: 0.000999, loss_supervised_2: 0.000919\n",
      "Train Epoch: 5 [33920/60000 (57%)]\tloss_supervised_1: 0.000471, loss_supervised_2: 0.001196\n",
      "Train Epoch: 5 [34560/60000 (58%)]\tloss_supervised_1: 0.001219, loss_supervised_2: 0.001258\n",
      "Train Epoch: 5 [35200/60000 (59%)]\tloss_supervised_1: 0.013329, loss_supervised_2: 0.007050\n",
      "Train Epoch: 5 [35840/60000 (60%)]\tloss_supervised_1: 0.000459, loss_supervised_2: 0.000460\n",
      "Train Epoch: 5 [36480/60000 (61%)]\tloss_supervised_1: 0.011288, loss_supervised_2: 0.008183\n",
      "Train Epoch: 5 [37120/60000 (62%)]\tloss_supervised_1: 0.060135, loss_supervised_2: 0.074807\n",
      "Train Epoch: 5 [37760/60000 (63%)]\tloss_supervised_1: 0.000922, loss_supervised_2: 0.001093\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tloss_supervised_1: 0.000631, loss_supervised_2: 0.000689\n",
      "Train Epoch: 5 [39040/60000 (65%)]\tloss_supervised_1: 0.013605, loss_supervised_2: 0.018031\n",
      "Train Epoch: 5 [39680/60000 (66%)]\tloss_supervised_1: 0.000316, loss_supervised_2: 0.000367\n",
      "Train Epoch: 5 [40320/60000 (67%)]\tloss_supervised_1: 0.000917, loss_supervised_2: 0.001160\n",
      "Train Epoch: 5 [40960/60000 (68%)]\tloss_supervised_1: 0.004187, loss_supervised_2: 0.003288\n",
      "Train Epoch: 5 [41600/60000 (69%)]\tloss_supervised_1: 0.001538, loss_supervised_2: 0.002234\n",
      "Train Epoch: 5 [42240/60000 (70%)]\tloss_supervised_1: 0.000835, loss_supervised_2: 0.001045\n",
      "Train Epoch: 5 [42880/60000 (71%)]\tloss_supervised_1: 0.029996, loss_supervised_2: 0.026272\n",
      "Train Epoch: 5 [43520/60000 (72%)]\tloss_supervised_1: 0.008125, loss_supervised_2: 0.016268\n",
      "Train Epoch: 5 [44160/60000 (74%)]\tloss_supervised_1: 0.002865, loss_supervised_2: 0.003015\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tloss_supervised_1: 0.001126, loss_supervised_2: 0.000746\n",
      "Train Epoch: 5 [45440/60000 (76%)]\tloss_supervised_1: 0.015359, loss_supervised_2: 0.011810\n",
      "Train Epoch: 5 [46080/60000 (77%)]\tloss_supervised_1: 0.004649, loss_supervised_2: 0.003680\n",
      "Train Epoch: 5 [46720/60000 (78%)]\tloss_supervised_1: 0.014009, loss_supervised_2: 0.017421\n",
      "Train Epoch: 5 [47360/60000 (79%)]\tloss_supervised_1: 0.001665, loss_supervised_2: 0.001337\n",
      "Train Epoch: 5 [48000/60000 (80%)]\tloss_supervised_1: 0.007583, loss_supervised_2: 0.008726\n",
      "Train Epoch: 5 [48640/60000 (81%)]\tloss_supervised_1: 0.003938, loss_supervised_2: 0.002676\n",
      "Train Epoch: 5 [49280/60000 (82%)]\tloss_supervised_1: 0.018884, loss_supervised_2: 0.021836\n",
      "Train Epoch: 5 [49920/60000 (83%)]\tloss_supervised_1: 0.000592, loss_supervised_2: 0.000511\n",
      "Train Epoch: 5 [50560/60000 (84%)]\tloss_supervised_1: 0.000359, loss_supervised_2: 0.000395\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tloss_supervised_1: 0.005401, loss_supervised_2: 0.001894\n",
      "Train Epoch: 5 [51840/60000 (86%)]\tloss_supervised_1: 0.018116, loss_supervised_2: 0.016534\n",
      "Train Epoch: 5 [52480/60000 (87%)]\tloss_supervised_1: 0.005139, loss_supervised_2: 0.003408\n",
      "Train Epoch: 5 [53120/60000 (88%)]\tloss_supervised_1: 0.021581, loss_supervised_2: 0.020633\n",
      "Train Epoch: 5 [53760/60000 (90%)]\tloss_supervised_1: 0.000155, loss_supervised_2: 0.000156\n",
      "Train Epoch: 5 [54400/60000 (91%)]\tloss_supervised_1: 0.001938, loss_supervised_2: 0.001164\n",
      "Train Epoch: 5 [55040/60000 (92%)]\tloss_supervised_1: 0.000475, loss_supervised_2: 0.000562\n",
      "Train Epoch: 5 [55680/60000 (93%)]\tloss_supervised_1: 0.037955, loss_supervised_2: 0.041389\n",
      "Train Epoch: 5 [56320/60000 (94%)]\tloss_supervised_1: 0.001644, loss_supervised_2: 0.000547\n",
      "Train Epoch: 5 [56960/60000 (95%)]\tloss_supervised_1: 0.002541, loss_supervised_2: 0.001693\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tloss_supervised_1: 0.005361, loss_supervised_2: 0.003736\n",
      "Train Epoch: 5 [58240/60000 (97%)]\tloss_supervised_1: 0.008029, loss_supervised_2: 0.009166\n",
      "Train Epoch: 5 [58880/60000 (98%)]\tloss_supervised_1: 0.044648, loss_supervised_2: 0.030411\n",
      "Train Epoch: 5 [59520/60000 (99%)]\tloss_supervised_1: 0.000292, loss_supervised_2: 0.000447\n",
      "Max entropy given\n",
      "\n",
      "Test: Avg. loss: 0.0419, Accuracy: 9869/10000 (99%)\n",
      "\n",
      "True y given\n",
      "\n",
      "Test: Avg. loss: 0.0078, Accuracy: 9978/10000 (100%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(99.7800)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))\n",
    "])\n",
    "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
    "\n",
    "f = Net().to(device)\n",
    "optimizer = optim.Adam(f.parameters(), lr=1e-3)\n",
    "\n",
    "test(f, test_loader)\n",
    "train(f, train_loader, optimizer, n_epochs)\n",
    "test(f, test_loader)\n",
    "test(f, test_loader, with_true_y=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ITTT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "\n",
    "def ttt_one_instance(x, f_ttt, f, optimizer, n_steps, y, n_classes=10):\n",
    "  f_ttt.load_state_dict(f.state_dict())  # reset f_ttt to f\n",
    "  f_ttt.train()\n",
    "  for step in range(n_steps): \n",
    "      \n",
    "    y0 = F.one_hot(torch.randint(0, n_classes, (x.shape[0],), device=device), num_classes=n_classes).float()\n",
    "    y1, z1 = f_ttt(x, y0)\n",
    "    y2, z2 = f.f2(z1, y1)\n",
    "    \n",
    "    loss_unsupervised_y = js_div(y1, y2)\n",
    "    loss_unsupervised_z = (z1 - z2).pow(2).mean()\n",
    "    loss = loss_unsupervised_y #+ loss_unsupervised_z\n",
    "        \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    if f_ttt.f2.fc2.weight.grad.var() == 0:\n",
    "        pass\n",
    "    optimizer.step()\n",
    "  return y1, y2\n",
    "\n",
    "def ttt(f, test_loader, n_steps, lr):\n",
    "  f_ttt = deepcopy(f)\n",
    "  f.eval()\n",
    "  optimizer = optim.Adam(f_ttt.parameters(), lr=lr)\n",
    "  test_loss_1, correct_1 = 0, 0\n",
    "  test_loss_2, correct_2 = 0, 0\n",
    "    \n",
    "  for ind, (data, target) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
    "    # print(f'batch {ind}/{len(test_loader)}:')\n",
    "    x, y = data.to(device), target.to(device)\n",
    "    y_hat_1, y_hat_2 = ttt_one_instance(x, f_ttt, f, optimizer, n_steps, y)\n",
    "\n",
    "    test_loss_1 += F.nll_loss(y_hat_1.log(), y, size_average=False).item()\n",
    "    test_loss_2 += F.nll_loss(y_hat_2.log(), y, size_average=False).item()\n",
    "\n",
    "    pred_1 = y_hat_1.data.max(1, keepdim=True)[1]\n",
    "    pred_2 = y_hat_2.data.max(1, keepdim=True)[1]\n",
    "\n",
    "    correct_1 += pred_1.eq(y.data.view_as(pred_1)).sum()\n",
    "    correct_2 += pred_2.eq(y.data.view_as(pred_2)).sum()\n",
    "\n",
    "  return correct_2 / len(test_loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, std, mean=0.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    AddGaussianNoise(1.75)])\n",
    "ood_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
    "ood_loader = torch.utils.data.DataLoader(ood_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max entropy given\n",
      "\n",
      "Test: Avg. loss: 0.7814, Accuracy: 7380/10000 (74%)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(73.8000)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(f, ood_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                                                                                                                       | 3/157 [00:00<00:19,  8.02it/s]"
     ]
    }
   ],
   "source": [
    "ttt(f, ood_loader, n_steps=10, lr=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
