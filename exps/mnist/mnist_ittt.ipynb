{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5Jzaqkb-acN",
        "outputId": "1f8ab22b-e8e7-4d4c-fb91-13ff07a45c48"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7805a2fe8d10>"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "from copy import deepcopy\n",
        "\n",
        "n_epochs = 5 # number of epochs for training\n",
        "batch_size_train = 1024 # batch size for training\n",
        "batch_size_test = 8192 # batch size for testing\n",
        "learning_rate = 0.001 # learning rate for Adam\n",
        "log_interval = 10 # logging interval for metrics\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\") # device for computation\n",
        "\n",
        "# fixing random seed\n",
        "random_seed = 1\n",
        "torch.backends.cudnn.enabled = False\n",
        "torch.manual_seed(random_seed)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "MsTQf0xB-jGr"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.f1 = F1()\n",
        "        self.f2 = F2()\n",
        "\n",
        "    def forward(self, x, y_hat, return_mid=False):\n",
        "        z = self.f1(x)\n",
        "        y_pred, z_pred  = self.f2(z, y_hat)\n",
        "        return y_pred, z_pred\n",
        "\n",
        "\n",
        "class F1(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(F1, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.activation = nn.LeakyReLU(negative_slope=0.01)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.activation(F.max_pool2d(self.conv1(x), 2))\n",
        "        x = self.activation(F.max_pool2d(self.conv2(x), 2))\n",
        "        x = x.view(-1, 320)\n",
        "        x = self.activation(self.fc1(x))\n",
        "        return x\n",
        "\n",
        "\n",
        "class F2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(F2, self).__init__()\n",
        "        self.fc2 = nn.Linear(50, 50)\n",
        "        self.fc3 = nn.Linear(50, 60)\n",
        "        self.y_hat_fc = nn.Linear(10, 50)\n",
        "        self.activation = nn.LeakyReLU(negative_slope=0.01)\n",
        "\n",
        "    def forward(self, x, y_hat):\n",
        "        x = x + self.activation(self.y_hat_fc(y_hat))\n",
        "        x = self.activation(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x[:, :10].softmax(-1), x[:, 10:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwvFCy-k-NbA"
      },
      "source": [
        "# Model Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "myir8Jdg-NbB"
      },
      "outputs": [],
      "source": [
        "def js_div(p, q):\n",
        "    m = 0.5 * (p + q)\n",
        "    return 0.5 * (F.kl_div(torch.log(p), m, reduction='batchmean') +\n",
        "                  F.kl_div(torch.log(q), m, reduction='batchmean'))\n",
        "\n",
        "def train(f, train_loader, optimizer, n_epochs, n_classes=10):\n",
        "  f.train()\n",
        "  for epoch in range(1, n_epochs + 1):\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "      # randomally choose y0 to be either the true target y or a random class\n",
        "      x, y = data.to(device), target.to(device)\n",
        "      y0_d = y if torch.rand(1) > 0.25 else torch.randint(0, n_classes, (x.shape[0],), device=device)\n",
        "      y0 = F.one_hot(y0_d, num_classes=n_classes).float()\n",
        "\n",
        "      # forward pass\n",
        "      y1, z1 = f(x, y0)\n",
        "      y2, z2 = f.f2(z1, y1)\n",
        "\n",
        "      # losses\n",
        "      loss_supervised_1 = F.nll_loss(y1.log(), y)\n",
        "      loss_supervised_2 = F.nll_loss(y2.log(), y)\n",
        "      loss = loss_supervised_1 + loss_supervised_2\n",
        "\n",
        "      # opt\n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "\n",
        "      # log\n",
        "      if batch_idx % log_interval == 0:\n",
        "        print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tloss_supervised_1: {:.6f}, loss_supervised_2: {:.6f}'.format(\n",
        "          epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "          100. * batch_idx / len(train_loader), loss_supervised_1.item(), loss_supervised_2.item()))\n",
        "        torch.save(f.state_dict(), './model.pth')\n",
        "        torch.save(optimizer.state_dict(), './optimizer.pth')\n",
        "\n",
        "\n",
        "def test(f, test_loader, n_classes=10, with_true_y=False):\n",
        "  f.eval()\n",
        "  test_loss, correct = 0, 0\n",
        "  with torch.no_grad():\n",
        "    for data, target in test_loader:\n",
        "      x, y = data.to(device), target.to(device)\n",
        "      if with_true_y:\n",
        "        y0 = F.one_hot(y, num_classes=n_classes).float()\n",
        "      else:\n",
        "        y0 = torch.ones((len(y), n_classes), device=x.device).to(device).softmax(-1)\n",
        "      y1, z1 = f(x, y0)\n",
        "      test_loss += F.nll_loss(y1.log(), y, size_average=False).item()\n",
        "      pred = y1.log().data.max(1, keepdim=True)[1]\n",
        "      correct += pred.eq(y.data.view_as(pred)).sum()\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  print(\"True y given\") if with_true_y else print(\"Max entropy given\")\n",
        "  print('\\nTest: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "    test_loss, correct, len(test_loader.dataset),\n",
        "    100. * correct / len(test_loader.dataset)))\n",
        "  return 100 * correct / len(test_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_IS4C6B_HMp",
        "outputId": "15eb94f1-8607-4e80-88ca-29e1a49fb168",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/torch/nn/_reduction.py:51: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max entropy given\n",
            "\n",
            "Test: Avg. loss: 2.3083, Accuracy: 1116/10000 (11%)\n",
            "\n",
            "Train Epoch: 1 [0/60000 (0%)]\tloss_supervised_1: 2.331868, loss_supervised_2: 2.319867\n",
            "Train Epoch: 1 [640/60000 (1%)]\tloss_supervised_1: 2.204759, loss_supervised_2: 2.281745\n",
            "Train Epoch: 1 [1280/60000 (2%)]\tloss_supervised_1: 1.895384, loss_supervised_2: 2.192101\n",
            "Train Epoch: 1 [1920/60000 (3%)]\tloss_supervised_1: 1.435428, loss_supervised_2: 1.861821\n",
            "Train Epoch: 1 [2560/60000 (4%)]\tloss_supervised_1: 0.848420, loss_supervised_2: 1.429704\n",
            "Train Epoch: 1 [3200/60000 (5%)]\tloss_supervised_1: 0.625035, loss_supervised_2: 0.932550\n",
            "Train Epoch: 1 [3840/60000 (6%)]\tloss_supervised_1: 0.508872, loss_supervised_2: 0.624582\n",
            "Train Epoch: 1 [4480/60000 (7%)]\tloss_supervised_1: 0.532531, loss_supervised_2: 0.624482\n",
            "Train Epoch: 1 [5120/60000 (9%)]\tloss_supervised_1: 0.569823, loss_supervised_2: 0.712636\n",
            "Train Epoch: 1 [5760/60000 (10%)]\tloss_supervised_1: 0.431731, loss_supervised_2: 0.530778\n",
            "Train Epoch: 1 [6400/60000 (11%)]\tloss_supervised_1: 0.780961, loss_supervised_2: 0.739781\n",
            "Train Epoch: 1 [7040/60000 (12%)]\tloss_supervised_1: 0.441009, loss_supervised_2: 0.456994\n",
            "Train Epoch: 1 [7680/60000 (13%)]\tloss_supervised_1: 0.496223, loss_supervised_2: 0.656478\n",
            "Train Epoch: 1 [8320/60000 (14%)]\tloss_supervised_1: 0.265768, loss_supervised_2: 0.330973\n",
            "Train Epoch: 1 [8960/60000 (15%)]\tloss_supervised_1: 0.104577, loss_supervised_2: 0.161225\n",
            "Train Epoch: 1 [9600/60000 (16%)]\tloss_supervised_1: 0.276518, loss_supervised_2: 0.279129\n",
            "Train Epoch: 1 [10240/60000 (17%)]\tloss_supervised_1: 0.078978, loss_supervised_2: 0.124276\n",
            "Train Epoch: 1 [10880/60000 (18%)]\tloss_supervised_1: 0.272468, loss_supervised_2: 0.338183\n",
            "Train Epoch: 1 [11520/60000 (19%)]\tloss_supervised_1: 0.204586, loss_supervised_2: 0.197686\n",
            "Train Epoch: 1 [12160/60000 (20%)]\tloss_supervised_1: 0.230809, loss_supervised_2: 0.263940\n",
            "Train Epoch: 1 [12800/60000 (21%)]\tloss_supervised_1: 0.192889, loss_supervised_2: 0.278603\n",
            "Train Epoch: 1 [13440/60000 (22%)]\tloss_supervised_1: 0.260194, loss_supervised_2: 0.246735\n",
            "Train Epoch: 1 [14080/60000 (23%)]\tloss_supervised_1: 0.136500, loss_supervised_2: 0.170940\n",
            "Train Epoch: 1 [14720/60000 (25%)]\tloss_supervised_1: 0.132575, loss_supervised_2: 0.132791\n",
            "Train Epoch: 1 [15360/60000 (26%)]\tloss_supervised_1: 0.229830, loss_supervised_2: 0.215425\n",
            "Train Epoch: 1 [16000/60000 (27%)]\tloss_supervised_1: 0.174775, loss_supervised_2: 0.223202\n",
            "Train Epoch: 1 [16640/60000 (28%)]\tloss_supervised_1: 0.162197, loss_supervised_2: 0.140159\n",
            "Train Epoch: 1 [17280/60000 (29%)]\tloss_supervised_1: 0.235681, loss_supervised_2: 0.266673\n",
            "Train Epoch: 1 [17920/60000 (30%)]\tloss_supervised_1: 0.180126, loss_supervised_2: 0.184888\n",
            "Train Epoch: 1 [18560/60000 (31%)]\tloss_supervised_1: 0.104346, loss_supervised_2: 0.121356\n",
            "Train Epoch: 1 [19200/60000 (32%)]\tloss_supervised_1: 0.161400, loss_supervised_2: 0.189978\n",
            "Train Epoch: 1 [19840/60000 (33%)]\tloss_supervised_1: 0.212098, loss_supervised_2: 0.242738\n",
            "Train Epoch: 1 [20480/60000 (34%)]\tloss_supervised_1: 0.259877, loss_supervised_2: 0.308028\n",
            "Train Epoch: 1 [21120/60000 (35%)]\tloss_supervised_1: 0.146107, loss_supervised_2: 0.138866\n",
            "Train Epoch: 1 [21760/60000 (36%)]\tloss_supervised_1: 0.205566, loss_supervised_2: 0.232306\n",
            "Train Epoch: 1 [22400/60000 (37%)]\tloss_supervised_1: 0.235747, loss_supervised_2: 0.225940\n",
            "Train Epoch: 1 [23040/60000 (38%)]\tloss_supervised_1: 0.114545, loss_supervised_2: 0.166148\n",
            "Train Epoch: 1 [23680/60000 (39%)]\tloss_supervised_1: 0.250862, loss_supervised_2: 0.290776\n",
            "Train Epoch: 1 [24320/60000 (41%)]\tloss_supervised_1: 0.061065, loss_supervised_2: 0.062584\n",
            "Train Epoch: 1 [24960/60000 (42%)]\tloss_supervised_1: 0.106066, loss_supervised_2: 0.138864\n",
            "Train Epoch: 1 [25600/60000 (43%)]\tloss_supervised_1: 0.279197, loss_supervised_2: 0.327307\n",
            "Train Epoch: 1 [26240/60000 (44%)]\tloss_supervised_1: 0.322740, loss_supervised_2: 0.381791\n",
            "Train Epoch: 1 [26880/60000 (45%)]\tloss_supervised_1: 0.043281, loss_supervised_2: 0.070839\n",
            "Train Epoch: 1 [27520/60000 (46%)]\tloss_supervised_1: 0.091715, loss_supervised_2: 0.083225\n",
            "Train Epoch: 1 [28160/60000 (47%)]\tloss_supervised_1: 0.062956, loss_supervised_2: 0.061166\n",
            "Train Epoch: 1 [28800/60000 (48%)]\tloss_supervised_1: 0.081136, loss_supervised_2: 0.080960\n",
            "Train Epoch: 1 [29440/60000 (49%)]\tloss_supervised_1: 0.137863, loss_supervised_2: 0.148015\n",
            "Train Epoch: 1 [30080/60000 (50%)]\tloss_supervised_1: 0.205181, loss_supervised_2: 0.214530\n",
            "Train Epoch: 1 [30720/60000 (51%)]\tloss_supervised_1: 0.092172, loss_supervised_2: 0.078260\n",
            "Train Epoch: 1 [31360/60000 (52%)]\tloss_supervised_1: 0.107133, loss_supervised_2: 0.132757\n",
            "Train Epoch: 1 [32000/60000 (53%)]\tloss_supervised_1: 0.032795, loss_supervised_2: 0.020333\n",
            "Train Epoch: 1 [32640/60000 (54%)]\tloss_supervised_1: 0.081527, loss_supervised_2: 0.071187\n",
            "Train Epoch: 1 [33280/60000 (55%)]\tloss_supervised_1: 0.017957, loss_supervised_2: 0.014516\n",
            "Train Epoch: 1 [33920/60000 (57%)]\tloss_supervised_1: 0.045248, loss_supervised_2: 0.038429\n",
            "Train Epoch: 1 [34560/60000 (58%)]\tloss_supervised_1: 0.123678, loss_supervised_2: 0.143180\n",
            "Train Epoch: 1 [35200/60000 (59%)]\tloss_supervised_1: 0.052649, loss_supervised_2: 0.035877\n",
            "Train Epoch: 1 [35840/60000 (60%)]\tloss_supervised_1: 0.047616, loss_supervised_2: 0.036115\n",
            "Train Epoch: 1 [36480/60000 (61%)]\tloss_supervised_1: 0.117466, loss_supervised_2: 0.171312\n",
            "Train Epoch: 1 [37120/60000 (62%)]\tloss_supervised_1: 0.089915, loss_supervised_2: 0.118828\n",
            "Train Epoch: 1 [37760/60000 (63%)]\tloss_supervised_1: 0.068244, loss_supervised_2: 0.064911\n",
            "Train Epoch: 1 [38400/60000 (64%)]\tloss_supervised_1: 0.057488, loss_supervised_2: 0.051179\n",
            "Train Epoch: 1 [39040/60000 (65%)]\tloss_supervised_1: 0.197490, loss_supervised_2: 0.198592\n",
            "Train Epoch: 1 [39680/60000 (66%)]\tloss_supervised_1: 0.038863, loss_supervised_2: 0.047104\n",
            "Train Epoch: 1 [40320/60000 (67%)]\tloss_supervised_1: 0.075361, loss_supervised_2: 0.062161\n",
            "Train Epoch: 1 [40960/60000 (68%)]\tloss_supervised_1: 0.080304, loss_supervised_2: 0.115471\n",
            "Train Epoch: 1 [41600/60000 (69%)]\tloss_supervised_1: 0.085036, loss_supervised_2: 0.066207\n",
            "Train Epoch: 1 [42240/60000 (70%)]\tloss_supervised_1: 0.094312, loss_supervised_2: 0.101581\n",
            "Train Epoch: 1 [42880/60000 (71%)]\tloss_supervised_1: 0.054120, loss_supervised_2: 0.036169\n",
            "Train Epoch: 1 [43520/60000 (72%)]\tloss_supervised_1: 0.024044, loss_supervised_2: 0.026757\n",
            "Train Epoch: 1 [44160/60000 (74%)]\tloss_supervised_1: 0.033992, loss_supervised_2: 0.023841\n",
            "Train Epoch: 1 [44800/60000 (75%)]\tloss_supervised_1: 0.062534, loss_supervised_2: 0.042627\n",
            "Train Epoch: 1 [45440/60000 (76%)]\tloss_supervised_1: 0.090809, loss_supervised_2: 0.078139\n",
            "Train Epoch: 1 [46080/60000 (77%)]\tloss_supervised_1: 0.166473, loss_supervised_2: 0.156054\n",
            "Train Epoch: 1 [46720/60000 (78%)]\tloss_supervised_1: 0.113072, loss_supervised_2: 0.103259\n",
            "Train Epoch: 1 [47360/60000 (79%)]\tloss_supervised_1: 0.054418, loss_supervised_2: 0.040829\n",
            "Train Epoch: 1 [48000/60000 (80%)]\tloss_supervised_1: 0.015304, loss_supervised_2: 0.019231\n",
            "Train Epoch: 1 [48640/60000 (81%)]\tloss_supervised_1: 0.030407, loss_supervised_2: 0.014640\n",
            "Train Epoch: 1 [49280/60000 (82%)]\tloss_supervised_1: 0.136913, loss_supervised_2: 0.163426\n",
            "Train Epoch: 1 [49920/60000 (83%)]\tloss_supervised_1: 0.126492, loss_supervised_2: 0.112655\n",
            "Train Epoch: 1 [50560/60000 (84%)]\tloss_supervised_1: 0.038051, loss_supervised_2: 0.044801\n",
            "Train Epoch: 1 [51200/60000 (85%)]\tloss_supervised_1: 0.136190, loss_supervised_2: 0.136920\n",
            "Train Epoch: 1 [51840/60000 (86%)]\tloss_supervised_1: 0.021958, loss_supervised_2: 0.014888\n",
            "Train Epoch: 1 [52480/60000 (87%)]\tloss_supervised_1: 0.042622, loss_supervised_2: 0.030743\n",
            "Train Epoch: 1 [53120/60000 (88%)]\tloss_supervised_1: 0.021679, loss_supervised_2: 0.028444\n",
            "Train Epoch: 1 [53760/60000 (90%)]\tloss_supervised_1: 0.091213, loss_supervised_2: 0.089817\n",
            "Train Epoch: 1 [54400/60000 (91%)]\tloss_supervised_1: 0.029023, loss_supervised_2: 0.017324\n",
            "Train Epoch: 1 [55040/60000 (92%)]\tloss_supervised_1: 0.130898, loss_supervised_2: 0.100602\n",
            "Train Epoch: 1 [55680/60000 (93%)]\tloss_supervised_1: 0.191887, loss_supervised_2: 0.229687\n",
            "Train Epoch: 1 [56320/60000 (94%)]\tloss_supervised_1: 0.103004, loss_supervised_2: 0.117479\n",
            "Train Epoch: 1 [56960/60000 (95%)]\tloss_supervised_1: 0.053952, loss_supervised_2: 0.052024\n",
            "Train Epoch: 1 [57600/60000 (96%)]\tloss_supervised_1: 0.008096, loss_supervised_2: 0.003288\n",
            "Train Epoch: 1 [58240/60000 (97%)]\tloss_supervised_1: 0.010648, loss_supervised_2: 0.004207\n",
            "Train Epoch: 1 [58880/60000 (98%)]\tloss_supervised_1: 0.020172, loss_supervised_2: 0.020943\n",
            "Train Epoch: 1 [59520/60000 (99%)]\tloss_supervised_1: 0.082573, loss_supervised_2: 0.106657\n",
            "Train Epoch: 2 [0/60000 (0%)]\tloss_supervised_1: 0.050897, loss_supervised_2: 0.032483\n",
            "Train Epoch: 2 [640/60000 (1%)]\tloss_supervised_1: 0.012511, loss_supervised_2: 0.006422\n",
            "Train Epoch: 2 [1280/60000 (2%)]\tloss_supervised_1: 0.125129, loss_supervised_2: 0.113490\n",
            "Train Epoch: 2 [1920/60000 (3%)]\tloss_supervised_1: 0.020124, loss_supervised_2: 0.011596\n",
            "Train Epoch: 2 [2560/60000 (4%)]\tloss_supervised_1: 0.078693, loss_supervised_2: 0.065323\n",
            "Train Epoch: 2 [3200/60000 (5%)]\tloss_supervised_1: 0.035923, loss_supervised_2: 0.027745\n",
            "Train Epoch: 2 [3840/60000 (6%)]\tloss_supervised_1: 0.101125, loss_supervised_2: 0.096901\n",
            "Train Epoch: 2 [4480/60000 (7%)]\tloss_supervised_1: 0.007321, loss_supervised_2: 0.007729\n",
            "Train Epoch: 2 [5120/60000 (9%)]\tloss_supervised_1: 0.033497, loss_supervised_2: 0.032349\n",
            "Train Epoch: 2 [5760/60000 (10%)]\tloss_supervised_1: 0.052542, loss_supervised_2: 0.058969\n",
            "Train Epoch: 2 [6400/60000 (11%)]\tloss_supervised_1: 0.069531, loss_supervised_2: 0.074159\n",
            "Train Epoch: 2 [7040/60000 (12%)]\tloss_supervised_1: 0.061508, loss_supervised_2: 0.080278\n",
            "Train Epoch: 2 [7680/60000 (13%)]\tloss_supervised_1: 0.077343, loss_supervised_2: 0.078963\n",
            "Train Epoch: 2 [8320/60000 (14%)]\tloss_supervised_1: 0.011754, loss_supervised_2: 0.006998\n",
            "Train Epoch: 2 [8960/60000 (15%)]\tloss_supervised_1: 0.006288, loss_supervised_2: 0.004432\n",
            "Train Epoch: 2 [9600/60000 (16%)]\tloss_supervised_1: 0.097860, loss_supervised_2: 0.122675\n",
            "Train Epoch: 2 [10240/60000 (17%)]\tloss_supervised_1: 0.061608, loss_supervised_2: 0.057067\n",
            "Train Epoch: 2 [10880/60000 (18%)]\tloss_supervised_1: 0.035813, loss_supervised_2: 0.043201\n",
            "Train Epoch: 2 [11520/60000 (19%)]\tloss_supervised_1: 0.071015, loss_supervised_2: 0.056790\n",
            "Train Epoch: 2 [12160/60000 (20%)]\tloss_supervised_1: 0.090567, loss_supervised_2: 0.090478\n",
            "Train Epoch: 2 [12800/60000 (21%)]\tloss_supervised_1: 0.103882, loss_supervised_2: 0.124956\n",
            "Train Epoch: 2 [13440/60000 (22%)]\tloss_supervised_1: 0.041963, loss_supervised_2: 0.023399\n",
            "Train Epoch: 2 [14080/60000 (23%)]\tloss_supervised_1: 0.051581, loss_supervised_2: 0.052111\n",
            "Train Epoch: 2 [14720/60000 (25%)]\tloss_supervised_1: 0.014388, loss_supervised_2: 0.013076\n",
            "Train Epoch: 2 [15360/60000 (26%)]\tloss_supervised_1: 0.005346, loss_supervised_2: 0.001385\n",
            "Train Epoch: 2 [16000/60000 (27%)]\tloss_supervised_1: 0.150324, loss_supervised_2: 0.166877\n",
            "Train Epoch: 2 [16640/60000 (28%)]\tloss_supervised_1: 0.170262, loss_supervised_2: 0.216430\n",
            "Train Epoch: 2 [17280/60000 (29%)]\tloss_supervised_1: 0.037187, loss_supervised_2: 0.055191\n",
            "Train Epoch: 2 [17920/60000 (30%)]\tloss_supervised_1: 0.041009, loss_supervised_2: 0.041733\n",
            "Train Epoch: 2 [18560/60000 (31%)]\tloss_supervised_1: 0.013706, loss_supervised_2: 0.007200\n",
            "Train Epoch: 2 [19200/60000 (32%)]\tloss_supervised_1: 0.010518, loss_supervised_2: 0.007249\n",
            "Train Epoch: 2 [19840/60000 (33%)]\tloss_supervised_1: 0.022966, loss_supervised_2: 0.020890\n",
            "Train Epoch: 2 [20480/60000 (34%)]\tloss_supervised_1: 0.072622, loss_supervised_2: 0.074048\n",
            "Train Epoch: 2 [21120/60000 (35%)]\tloss_supervised_1: 0.157025, loss_supervised_2: 0.217974\n",
            "Train Epoch: 2 [21760/60000 (36%)]\tloss_supervised_1: 0.096830, loss_supervised_2: 0.147263\n",
            "Train Epoch: 2 [22400/60000 (37%)]\tloss_supervised_1: 0.006445, loss_supervised_2: 0.002396\n",
            "Train Epoch: 2 [23040/60000 (38%)]\tloss_supervised_1: 0.054132, loss_supervised_2: 0.054134\n",
            "Train Epoch: 2 [23680/60000 (39%)]\tloss_supervised_1: 0.016371, loss_supervised_2: 0.020495\n",
            "Train Epoch: 2 [24320/60000 (41%)]\tloss_supervised_1: 0.030723, loss_supervised_2: 0.046075\n",
            "Train Epoch: 2 [24960/60000 (42%)]\tloss_supervised_1: 0.053432, loss_supervised_2: 0.088520\n",
            "Train Epoch: 2 [25600/60000 (43%)]\tloss_supervised_1: 0.022797, loss_supervised_2: 0.023700\n",
            "Train Epoch: 2 [26240/60000 (44%)]\tloss_supervised_1: 0.019732, loss_supervised_2: 0.016137\n",
            "Train Epoch: 2 [26880/60000 (45%)]\tloss_supervised_1: 0.063127, loss_supervised_2: 0.095761\n",
            "Train Epoch: 2 [27520/60000 (46%)]\tloss_supervised_1: 0.096042, loss_supervised_2: 0.082529\n",
            "Train Epoch: 2 [28160/60000 (47%)]\tloss_supervised_1: 0.006722, loss_supervised_2: 0.002152\n",
            "Train Epoch: 2 [28800/60000 (48%)]\tloss_supervised_1: 0.009320, loss_supervised_2: 0.003698\n",
            "Train Epoch: 2 [29440/60000 (49%)]\tloss_supervised_1: 0.038478, loss_supervised_2: 0.024739\n",
            "Train Epoch: 2 [30080/60000 (50%)]\tloss_supervised_1: 0.006530, loss_supervised_2: 0.002083\n",
            "Train Epoch: 2 [30720/60000 (51%)]\tloss_supervised_1: 0.085365, loss_supervised_2: 0.101463\n",
            "Train Epoch: 2 [31360/60000 (52%)]\tloss_supervised_1: 0.027214, loss_supervised_2: 0.020530\n",
            "Train Epoch: 2 [32000/60000 (53%)]\tloss_supervised_1: 0.037892, loss_supervised_2: 0.052484\n",
            "Train Epoch: 2 [32640/60000 (54%)]\tloss_supervised_1: 0.049417, loss_supervised_2: 0.075904\n",
            "Train Epoch: 2 [33280/60000 (55%)]\tloss_supervised_1: 0.082855, loss_supervised_2: 0.089699\n",
            "Train Epoch: 2 [33920/60000 (57%)]\tloss_supervised_1: 0.139200, loss_supervised_2: 0.191678\n",
            "Train Epoch: 2 [34560/60000 (58%)]\tloss_supervised_1: 0.131659, loss_supervised_2: 0.130755\n",
            "Train Epoch: 2 [35200/60000 (59%)]\tloss_supervised_1: 0.011948, loss_supervised_2: 0.007306\n",
            "Train Epoch: 2 [35840/60000 (60%)]\tloss_supervised_1: 0.005557, loss_supervised_2: 0.002862\n",
            "Train Epoch: 2 [36480/60000 (61%)]\tloss_supervised_1: 0.003133, loss_supervised_2: 0.001463\n",
            "Train Epoch: 2 [37120/60000 (62%)]\tloss_supervised_1: 0.041570, loss_supervised_2: 0.024576\n",
            "Train Epoch: 2 [37760/60000 (63%)]\tloss_supervised_1: 0.087017, loss_supervised_2: 0.079285\n",
            "Train Epoch: 2 [38400/60000 (64%)]\tloss_supervised_1: 0.135535, loss_supervised_2: 0.152046\n",
            "Train Epoch: 2 [39040/60000 (65%)]\tloss_supervised_1: 0.078118, loss_supervised_2: 0.128858\n",
            "Train Epoch: 2 [39680/60000 (66%)]\tloss_supervised_1: 0.010043, loss_supervised_2: 0.004581\n",
            "Train Epoch: 2 [40320/60000 (67%)]\tloss_supervised_1: 0.137331, loss_supervised_2: 0.158124\n",
            "Train Epoch: 2 [40960/60000 (68%)]\tloss_supervised_1: 0.006407, loss_supervised_2: 0.002572\n",
            "Train Epoch: 2 [41600/60000 (69%)]\tloss_supervised_1: 0.008641, loss_supervised_2: 0.005087\n",
            "Train Epoch: 2 [42240/60000 (70%)]\tloss_supervised_1: 0.078417, loss_supervised_2: 0.092203\n",
            "Train Epoch: 2 [42880/60000 (71%)]\tloss_supervised_1: 0.013192, loss_supervised_2: 0.005670\n",
            "Train Epoch: 2 [43520/60000 (72%)]\tloss_supervised_1: 0.071986, loss_supervised_2: 0.085344\n",
            "Train Epoch: 2 [44160/60000 (74%)]\tloss_supervised_1: 0.025578, loss_supervised_2: 0.052004\n",
            "Train Epoch: 2 [44800/60000 (75%)]\tloss_supervised_1: 0.111153, loss_supervised_2: 0.119938\n",
            "Train Epoch: 2 [45440/60000 (76%)]\tloss_supervised_1: 0.007957, loss_supervised_2: 0.004289\n",
            "Train Epoch: 2 [46080/60000 (77%)]\tloss_supervised_1: 0.123089, loss_supervised_2: 0.110324\n",
            "Train Epoch: 2 [46720/60000 (78%)]\tloss_supervised_1: 0.015274, loss_supervised_2: 0.009020\n",
            "Train Epoch: 2 [47360/60000 (79%)]\tloss_supervised_1: 0.016374, loss_supervised_2: 0.008425\n",
            "Train Epoch: 2 [48000/60000 (80%)]\tloss_supervised_1: 0.050823, loss_supervised_2: 0.080382\n",
            "Train Epoch: 2 [48640/60000 (81%)]\tloss_supervised_1: 0.017721, loss_supervised_2: 0.006380\n",
            "Train Epoch: 2 [49280/60000 (82%)]\tloss_supervised_1: 0.009979, loss_supervised_2: 0.004186\n",
            "Train Epoch: 2 [49920/60000 (83%)]\tloss_supervised_1: 0.021984, loss_supervised_2: 0.015544\n",
            "Train Epoch: 2 [50560/60000 (84%)]\tloss_supervised_1: 0.108695, loss_supervised_2: 0.115364\n",
            "Train Epoch: 2 [51200/60000 (85%)]\tloss_supervised_1: 0.050207, loss_supervised_2: 0.039361\n",
            "Train Epoch: 2 [51840/60000 (86%)]\tloss_supervised_1: 0.005230, loss_supervised_2: 0.002676\n",
            "Train Epoch: 2 [52480/60000 (87%)]\tloss_supervised_1: 0.004120, loss_supervised_2: 0.002248\n",
            "Train Epoch: 2 [53120/60000 (88%)]\tloss_supervised_1: 0.067411, loss_supervised_2: 0.062659\n",
            "Train Epoch: 2 [53760/60000 (90%)]\tloss_supervised_1: 0.010863, loss_supervised_2: 0.007909\n",
            "Train Epoch: 2 [54400/60000 (91%)]\tloss_supervised_1: 0.088321, loss_supervised_2: 0.086777\n",
            "Train Epoch: 2 [55040/60000 (92%)]\tloss_supervised_1: 0.014211, loss_supervised_2: 0.017868\n",
            "Train Epoch: 2 [55680/60000 (93%)]\tloss_supervised_1: 0.016686, loss_supervised_2: 0.007928\n",
            "Train Epoch: 2 [56320/60000 (94%)]\tloss_supervised_1: 0.025989, loss_supervised_2: 0.042355\n",
            "Train Epoch: 2 [56960/60000 (95%)]\tloss_supervised_1: 0.036698, loss_supervised_2: 0.024183\n",
            "Train Epoch: 2 [57600/60000 (96%)]\tloss_supervised_1: 0.044907, loss_supervised_2: 0.069686\n",
            "Train Epoch: 2 [58240/60000 (97%)]\tloss_supervised_1: 0.188405, loss_supervised_2: 0.199006\n",
            "Train Epoch: 2 [58880/60000 (98%)]\tloss_supervised_1: 0.016529, loss_supervised_2: 0.017971\n",
            "Train Epoch: 2 [59520/60000 (99%)]\tloss_supervised_1: 0.041863, loss_supervised_2: 0.031466\n",
            "Train Epoch: 3 [0/60000 (0%)]\tloss_supervised_1: 0.070216, loss_supervised_2: 0.036772\n",
            "Train Epoch: 3 [640/60000 (1%)]\tloss_supervised_1: 0.113524, loss_supervised_2: 0.134742\n",
            "Train Epoch: 3 [1280/60000 (2%)]\tloss_supervised_1: 0.005487, loss_supervised_2: 0.007189\n",
            "Train Epoch: 3 [1920/60000 (3%)]\tloss_supervised_1: 0.018008, loss_supervised_2: 0.020223\n",
            "Train Epoch: 3 [2560/60000 (4%)]\tloss_supervised_1: 0.016496, loss_supervised_2: 0.008487\n",
            "Train Epoch: 3 [3200/60000 (5%)]\tloss_supervised_1: 0.013611, loss_supervised_2: 0.007009\n",
            "Train Epoch: 3 [3840/60000 (6%)]\tloss_supervised_1: 0.037526, loss_supervised_2: 0.035922\n",
            "Train Epoch: 3 [4480/60000 (7%)]\tloss_supervised_1: 0.003575, loss_supervised_2: 0.002238\n",
            "Train Epoch: 3 [5120/60000 (9%)]\tloss_supervised_1: 0.013527, loss_supervised_2: 0.023239\n",
            "Train Epoch: 3 [5760/60000 (10%)]\tloss_supervised_1: 0.060030, loss_supervised_2: 0.047071\n",
            "Train Epoch: 3 [6400/60000 (11%)]\tloss_supervised_1: 0.035181, loss_supervised_2: 0.030001\n",
            "Train Epoch: 3 [7040/60000 (12%)]\tloss_supervised_1: 0.035036, loss_supervised_2: 0.036385\n",
            "Train Epoch: 3 [7680/60000 (13%)]\tloss_supervised_1: 0.051275, loss_supervised_2: 0.048868\n",
            "Train Epoch: 3 [8320/60000 (14%)]\tloss_supervised_1: 0.072653, loss_supervised_2: 0.113099\n",
            "Train Epoch: 3 [8960/60000 (15%)]\tloss_supervised_1: 0.010733, loss_supervised_2: 0.012397\n",
            "Train Epoch: 3 [9600/60000 (16%)]\tloss_supervised_1: 0.006947, loss_supervised_2: 0.002414\n",
            "Train Epoch: 3 [10240/60000 (17%)]\tloss_supervised_1: 0.034850, loss_supervised_2: 0.039874\n",
            "Train Epoch: 3 [10880/60000 (18%)]\tloss_supervised_1: 0.243158, loss_supervised_2: 0.224617\n",
            "Train Epoch: 3 [11520/60000 (19%)]\tloss_supervised_1: 0.001968, loss_supervised_2: 0.000822\n",
            "Train Epoch: 3 [12160/60000 (20%)]\tloss_supervised_1: 0.002423, loss_supervised_2: 0.001968\n",
            "Train Epoch: 3 [12800/60000 (21%)]\tloss_supervised_1: 0.188586, loss_supervised_2: 0.217504\n",
            "Train Epoch: 3 [13440/60000 (22%)]\tloss_supervised_1: 0.002780, loss_supervised_2: 0.002329\n",
            "Train Epoch: 3 [14080/60000 (23%)]\tloss_supervised_1: 0.019027, loss_supervised_2: 0.022928\n",
            "Train Epoch: 3 [14720/60000 (25%)]\tloss_supervised_1: 0.044584, loss_supervised_2: 0.033378\n",
            "Train Epoch: 3 [15360/60000 (26%)]\tloss_supervised_1: 0.006341, loss_supervised_2: 0.006192\n",
            "Train Epoch: 3 [16000/60000 (27%)]\tloss_supervised_1: 0.137907, loss_supervised_2: 0.167057\n",
            "Train Epoch: 3 [16640/60000 (28%)]\tloss_supervised_1: 0.014023, loss_supervised_2: 0.004457\n",
            "Train Epoch: 3 [17280/60000 (29%)]\tloss_supervised_1: 0.048154, loss_supervised_2: 0.077657\n",
            "Train Epoch: 3 [17920/60000 (30%)]\tloss_supervised_1: 0.002868, loss_supervised_2: 0.001946\n",
            "Train Epoch: 3 [18560/60000 (31%)]\tloss_supervised_1: 0.029467, loss_supervised_2: 0.053256\n",
            "Train Epoch: 3 [19200/60000 (32%)]\tloss_supervised_1: 0.140804, loss_supervised_2: 0.160121\n",
            "Train Epoch: 3 [19840/60000 (33%)]\tloss_supervised_1: 0.071414, loss_supervised_2: 0.085589\n",
            "Train Epoch: 3 [20480/60000 (34%)]\tloss_supervised_1: 0.009703, loss_supervised_2: 0.007086\n",
            "Train Epoch: 3 [21120/60000 (35%)]\tloss_supervised_1: 0.025966, loss_supervised_2: 0.020794\n",
            "Train Epoch: 3 [21760/60000 (36%)]\tloss_supervised_1: 0.013934, loss_supervised_2: 0.013333\n",
            "Train Epoch: 3 [22400/60000 (37%)]\tloss_supervised_1: 0.072504, loss_supervised_2: 0.092390\n",
            "Train Epoch: 3 [23040/60000 (38%)]\tloss_supervised_1: 0.046821, loss_supervised_2: 0.049731\n",
            "Train Epoch: 3 [23680/60000 (39%)]\tloss_supervised_1: 0.005356, loss_supervised_2: 0.002841\n",
            "Train Epoch: 3 [24320/60000 (41%)]\tloss_supervised_1: 0.004968, loss_supervised_2: 0.001987\n",
            "Train Epoch: 3 [24960/60000 (42%)]\tloss_supervised_1: 0.216017, loss_supervised_2: 0.266069\n",
            "Train Epoch: 3 [25600/60000 (43%)]\tloss_supervised_1: 0.007903, loss_supervised_2: 0.004827\n",
            "Train Epoch: 3 [26240/60000 (44%)]\tloss_supervised_1: 0.013936, loss_supervised_2: 0.011479\n",
            "Train Epoch: 3 [26880/60000 (45%)]\tloss_supervised_1: 0.003538, loss_supervised_2: 0.002676\n",
            "Train Epoch: 3 [27520/60000 (46%)]\tloss_supervised_1: 0.015297, loss_supervised_2: 0.009178\n",
            "Train Epoch: 3 [28160/60000 (47%)]\tloss_supervised_1: 0.033370, loss_supervised_2: 0.038559\n",
            "Train Epoch: 3 [28800/60000 (48%)]\tloss_supervised_1: 0.073677, loss_supervised_2: 0.050310\n",
            "Train Epoch: 3 [29440/60000 (49%)]\tloss_supervised_1: 0.004367, loss_supervised_2: 0.003198\n",
            "Train Epoch: 3 [30080/60000 (50%)]\tloss_supervised_1: 0.017420, loss_supervised_2: 0.012336\n",
            "Train Epoch: 3 [30720/60000 (51%)]\tloss_supervised_1: 0.003003, loss_supervised_2: 0.002297\n",
            "Train Epoch: 3 [31360/60000 (52%)]\tloss_supervised_1: 0.264471, loss_supervised_2: 0.387127\n",
            "Train Epoch: 3 [32000/60000 (53%)]\tloss_supervised_1: 0.021767, loss_supervised_2: 0.010081\n",
            "Train Epoch: 3 [32640/60000 (54%)]\tloss_supervised_1: 0.013139, loss_supervised_2: 0.014303\n",
            "Train Epoch: 3 [33280/60000 (55%)]\tloss_supervised_1: 0.001023, loss_supervised_2: 0.000893\n",
            "Train Epoch: 3 [33920/60000 (57%)]\tloss_supervised_1: 0.046224, loss_supervised_2: 0.060132\n",
            "Train Epoch: 3 [34560/60000 (58%)]\tloss_supervised_1: 0.015449, loss_supervised_2: 0.026766\n",
            "Train Epoch: 3 [35200/60000 (59%)]\tloss_supervised_1: 0.012713, loss_supervised_2: 0.013615\n",
            "Train Epoch: 3 [35840/60000 (60%)]\tloss_supervised_1: 0.008538, loss_supervised_2: 0.003846\n",
            "Train Epoch: 3 [36480/60000 (61%)]\tloss_supervised_1: 0.051094, loss_supervised_2: 0.039948\n",
            "Train Epoch: 3 [37120/60000 (62%)]\tloss_supervised_1: 0.099133, loss_supervised_2: 0.115614\n",
            "Train Epoch: 3 [37760/60000 (63%)]\tloss_supervised_1: 0.022956, loss_supervised_2: 0.019183\n",
            "Train Epoch: 3 [38400/60000 (64%)]\tloss_supervised_1: 0.067875, loss_supervised_2: 0.083922\n",
            "Train Epoch: 3 [39040/60000 (65%)]\tloss_supervised_1: 0.029989, loss_supervised_2: 0.018726\n",
            "Train Epoch: 3 [39680/60000 (66%)]\tloss_supervised_1: 0.001715, loss_supervised_2: 0.000878\n",
            "Train Epoch: 3 [40320/60000 (67%)]\tloss_supervised_1: 0.003440, loss_supervised_2: 0.001110\n",
            "Train Epoch: 3 [40960/60000 (68%)]\tloss_supervised_1: 0.008673, loss_supervised_2: 0.001960\n",
            "Train Epoch: 3 [41600/60000 (69%)]\tloss_supervised_1: 0.009360, loss_supervised_2: 0.008755\n",
            "Train Epoch: 3 [42240/60000 (70%)]\tloss_supervised_1: 0.065980, loss_supervised_2: 0.059321\n",
            "Train Epoch: 3 [42880/60000 (71%)]\tloss_supervised_1: 0.002177, loss_supervised_2: 0.001226\n",
            "Train Epoch: 3 [43520/60000 (72%)]\tloss_supervised_1: 0.059421, loss_supervised_2: 0.047111\n",
            "Train Epoch: 3 [44160/60000 (74%)]\tloss_supervised_1: 0.068850, loss_supervised_2: 0.064774\n",
            "Train Epoch: 3 [44800/60000 (75%)]\tloss_supervised_1: 0.017404, loss_supervised_2: 0.022195\n",
            "Train Epoch: 3 [45440/60000 (76%)]\tloss_supervised_1: 0.025270, loss_supervised_2: 0.029932\n",
            "Train Epoch: 3 [46080/60000 (77%)]\tloss_supervised_1: 0.128326, loss_supervised_2: 0.183170\n",
            "Train Epoch: 3 [46720/60000 (78%)]\tloss_supervised_1: 0.034433, loss_supervised_2: 0.055664\n",
            "Train Epoch: 3 [47360/60000 (79%)]\tloss_supervised_1: 0.105190, loss_supervised_2: 0.122759\n",
            "Train Epoch: 3 [48000/60000 (80%)]\tloss_supervised_1: 0.024263, loss_supervised_2: 0.016388\n",
            "Train Epoch: 3 [48640/60000 (81%)]\tloss_supervised_1: 0.004504, loss_supervised_2: 0.004992\n",
            "Train Epoch: 3 [49280/60000 (82%)]\tloss_supervised_1: 0.007812, loss_supervised_2: 0.006059\n",
            "Train Epoch: 3 [49920/60000 (83%)]\tloss_supervised_1: 0.040150, loss_supervised_2: 0.063147\n",
            "Train Epoch: 3 [50560/60000 (84%)]\tloss_supervised_1: 0.048090, loss_supervised_2: 0.047797\n",
            "Train Epoch: 3 [51200/60000 (85%)]\tloss_supervised_1: 0.005452, loss_supervised_2: 0.005970\n",
            "Train Epoch: 3 [51840/60000 (86%)]\tloss_supervised_1: 0.037223, loss_supervised_2: 0.042466\n",
            "Train Epoch: 3 [52480/60000 (87%)]\tloss_supervised_1: 0.129840, loss_supervised_2: 0.180552\n",
            "Train Epoch: 3 [53120/60000 (88%)]\tloss_supervised_1: 0.004034, loss_supervised_2: 0.005874\n",
            "Train Epoch: 3 [53760/60000 (90%)]\tloss_supervised_1: 0.001840, loss_supervised_2: 0.001452\n",
            "Train Epoch: 3 [54400/60000 (91%)]\tloss_supervised_1: 0.008715, loss_supervised_2: 0.005944\n",
            "Train Epoch: 3 [55040/60000 (92%)]\tloss_supervised_1: 0.017689, loss_supervised_2: 0.009721\n",
            "Train Epoch: 3 [55680/60000 (93%)]\tloss_supervised_1: 0.106140, loss_supervised_2: 0.163855\n",
            "Train Epoch: 3 [56320/60000 (94%)]\tloss_supervised_1: 0.001191, loss_supervised_2: 0.000694\n",
            "Train Epoch: 3 [56960/60000 (95%)]\tloss_supervised_1: 0.008316, loss_supervised_2: 0.005261\n",
            "Train Epoch: 3 [57600/60000 (96%)]\tloss_supervised_1: 0.002663, loss_supervised_2: 0.003850\n",
            "Train Epoch: 3 [58240/60000 (97%)]\tloss_supervised_1: 0.012407, loss_supervised_2: 0.007690\n",
            "Train Epoch: 3 [58880/60000 (98%)]\tloss_supervised_1: 0.004527, loss_supervised_2: 0.002800\n",
            "Train Epoch: 3 [59520/60000 (99%)]\tloss_supervised_1: 0.013225, loss_supervised_2: 0.008061\n",
            "Train Epoch: 4 [0/60000 (0%)]\tloss_supervised_1: 0.005739, loss_supervised_2: 0.003759\n",
            "Train Epoch: 4 [640/60000 (1%)]\tloss_supervised_1: 0.056736, loss_supervised_2: 0.100268\n",
            "Train Epoch: 4 [1280/60000 (2%)]\tloss_supervised_1: 0.004114, loss_supervised_2: 0.002439\n",
            "Train Epoch: 4 [1920/60000 (3%)]\tloss_supervised_1: 0.045775, loss_supervised_2: 0.030062\n",
            "Train Epoch: 4 [2560/60000 (4%)]\tloss_supervised_1: 0.013865, loss_supervised_2: 0.014626\n",
            "Train Epoch: 4 [3200/60000 (5%)]\tloss_supervised_1: 0.085091, loss_supervised_2: 0.100892\n",
            "Train Epoch: 4 [3840/60000 (6%)]\tloss_supervised_1: 0.051691, loss_supervised_2: 0.051846\n",
            "Train Epoch: 4 [4480/60000 (7%)]\tloss_supervised_1: 0.096490, loss_supervised_2: 0.126169\n",
            "Train Epoch: 4 [5120/60000 (9%)]\tloss_supervised_1: 0.031346, loss_supervised_2: 0.037892\n",
            "Train Epoch: 4 [5760/60000 (10%)]\tloss_supervised_1: 0.030552, loss_supervised_2: 0.040587\n",
            "Train Epoch: 4 [6400/60000 (11%)]\tloss_supervised_1: 0.062201, loss_supervised_2: 0.061152\n",
            "Train Epoch: 4 [7040/60000 (12%)]\tloss_supervised_1: 0.017299, loss_supervised_2: 0.021612\n",
            "Train Epoch: 4 [7680/60000 (13%)]\tloss_supervised_1: 0.059112, loss_supervised_2: 0.074192\n",
            "Train Epoch: 4 [8320/60000 (14%)]\tloss_supervised_1: 0.003760, loss_supervised_2: 0.002157\n",
            "Train Epoch: 4 [8960/60000 (15%)]\tloss_supervised_1: 0.002461, loss_supervised_2: 0.002019\n",
            "Train Epoch: 4 [9600/60000 (16%)]\tloss_supervised_1: 0.027386, loss_supervised_2: 0.029620\n",
            "Train Epoch: 4 [10240/60000 (17%)]\tloss_supervised_1: 0.019004, loss_supervised_2: 0.027442\n",
            "Train Epoch: 4 [10880/60000 (18%)]\tloss_supervised_1: 0.003333, loss_supervised_2: 0.001476\n",
            "Train Epoch: 4 [11520/60000 (19%)]\tloss_supervised_1: 0.004154, loss_supervised_2: 0.003594\n",
            "Train Epoch: 4 [12160/60000 (20%)]\tloss_supervised_1: 0.003828, loss_supervised_2: 0.002112\n",
            "Train Epoch: 4 [12800/60000 (21%)]\tloss_supervised_1: 0.002098, loss_supervised_2: 0.000980\n",
            "Train Epoch: 4 [13440/60000 (22%)]\tloss_supervised_1: 0.007508, loss_supervised_2: 0.008806\n",
            "Train Epoch: 4 [14080/60000 (23%)]\tloss_supervised_1: 0.022743, loss_supervised_2: 0.035734\n",
            "Train Epoch: 4 [14720/60000 (25%)]\tloss_supervised_1: 0.016633, loss_supervised_2: 0.016275\n",
            "Train Epoch: 4 [15360/60000 (26%)]\tloss_supervised_1: 0.006427, loss_supervised_2: 0.008062\n",
            "Train Epoch: 4 [16000/60000 (27%)]\tloss_supervised_1: 0.001459, loss_supervised_2: 0.000917\n",
            "Train Epoch: 4 [16640/60000 (28%)]\tloss_supervised_1: 0.017072, loss_supervised_2: 0.024170\n",
            "Train Epoch: 4 [17280/60000 (29%)]\tloss_supervised_1: 0.031269, loss_supervised_2: 0.018775\n",
            "Train Epoch: 4 [17920/60000 (30%)]\tloss_supervised_1: 0.020051, loss_supervised_2: 0.013190\n",
            "Train Epoch: 4 [18560/60000 (31%)]\tloss_supervised_1: 0.001175, loss_supervised_2: 0.000734\n",
            "Train Epoch: 4 [19200/60000 (32%)]\tloss_supervised_1: 0.001166, loss_supervised_2: 0.000931\n",
            "Train Epoch: 4 [19840/60000 (33%)]\tloss_supervised_1: 0.002008, loss_supervised_2: 0.001057\n",
            "Train Epoch: 4 [20480/60000 (34%)]\tloss_supervised_1: 0.063970, loss_supervised_2: 0.138979\n",
            "Train Epoch: 4 [21120/60000 (35%)]\tloss_supervised_1: 0.008804, loss_supervised_2: 0.008320\n",
            "Train Epoch: 4 [21760/60000 (36%)]\tloss_supervised_1: 0.005844, loss_supervised_2: 0.004108\n",
            "Train Epoch: 4 [22400/60000 (37%)]\tloss_supervised_1: 0.002744, loss_supervised_2: 0.002251\n",
            "Train Epoch: 4 [23040/60000 (38%)]\tloss_supervised_1: 0.039469, loss_supervised_2: 0.032033\n",
            "Train Epoch: 4 [23680/60000 (39%)]\tloss_supervised_1: 0.048535, loss_supervised_2: 0.093160\n",
            "Train Epoch: 4 [24320/60000 (41%)]\tloss_supervised_1: 0.009672, loss_supervised_2: 0.004423\n",
            "Train Epoch: 4 [24960/60000 (42%)]\tloss_supervised_1: 0.060718, loss_supervised_2: 0.062358\n",
            "Train Epoch: 4 [25600/60000 (43%)]\tloss_supervised_1: 0.004215, loss_supervised_2: 0.008654\n",
            "Train Epoch: 4 [26240/60000 (44%)]\tloss_supervised_1: 0.086663, loss_supervised_2: 0.134664\n",
            "Train Epoch: 4 [26880/60000 (45%)]\tloss_supervised_1: 0.013971, loss_supervised_2: 0.022709\n",
            "Train Epoch: 4 [27520/60000 (46%)]\tloss_supervised_1: 0.006309, loss_supervised_2: 0.004752\n",
            "Train Epoch: 4 [28160/60000 (47%)]\tloss_supervised_1: 0.060856, loss_supervised_2: 0.097811\n",
            "Train Epoch: 4 [28800/60000 (48%)]\tloss_supervised_1: 0.032688, loss_supervised_2: 0.029997\n",
            "Train Epoch: 4 [29440/60000 (49%)]\tloss_supervised_1: 0.009374, loss_supervised_2: 0.009357\n",
            "Train Epoch: 4 [30080/60000 (50%)]\tloss_supervised_1: 0.104233, loss_supervised_2: 0.110517\n",
            "Train Epoch: 4 [30720/60000 (51%)]\tloss_supervised_1: 0.153551, loss_supervised_2: 0.185447\n",
            "Train Epoch: 4 [31360/60000 (52%)]\tloss_supervised_1: 0.018749, loss_supervised_2: 0.016715\n",
            "Train Epoch: 4 [32000/60000 (53%)]\tloss_supervised_1: 0.002166, loss_supervised_2: 0.002118\n",
            "Train Epoch: 4 [32640/60000 (54%)]\tloss_supervised_1: 0.001785, loss_supervised_2: 0.001563\n",
            "Train Epoch: 4 [33280/60000 (55%)]\tloss_supervised_1: 0.002473, loss_supervised_2: 0.001314\n",
            "Train Epoch: 4 [33920/60000 (57%)]\tloss_supervised_1: 0.002120, loss_supervised_2: 0.002261\n",
            "Train Epoch: 4 [34560/60000 (58%)]\tloss_supervised_1: 0.001811, loss_supervised_2: 0.001052\n",
            "Train Epoch: 4 [35200/60000 (59%)]\tloss_supervised_1: 0.039415, loss_supervised_2: 0.034404\n",
            "Train Epoch: 4 [35840/60000 (60%)]\tloss_supervised_1: 0.002974, loss_supervised_2: 0.003347\n",
            "Train Epoch: 4 [36480/60000 (61%)]\tloss_supervised_1: 0.005142, loss_supervised_2: 0.005530\n",
            "Train Epoch: 4 [37120/60000 (62%)]\tloss_supervised_1: 0.069710, loss_supervised_2: 0.086388\n",
            "Train Epoch: 4 [37760/60000 (63%)]\tloss_supervised_1: 0.002223, loss_supervised_2: 0.002100\n",
            "Train Epoch: 4 [38400/60000 (64%)]\tloss_supervised_1: 0.052459, loss_supervised_2: 0.089544\n",
            "Train Epoch: 4 [39040/60000 (65%)]\tloss_supervised_1: 0.009083, loss_supervised_2: 0.007890\n",
            "Train Epoch: 4 [39680/60000 (66%)]\tloss_supervised_1: 0.003359, loss_supervised_2: 0.007926\n",
            "Train Epoch: 4 [40320/60000 (67%)]\tloss_supervised_1: 0.000342, loss_supervised_2: 0.000608\n",
            "Train Epoch: 4 [40960/60000 (68%)]\tloss_supervised_1: 0.001024, loss_supervised_2: 0.000926\n",
            "Train Epoch: 4 [41600/60000 (69%)]\tloss_supervised_1: 0.006906, loss_supervised_2: 0.002511\n",
            "Train Epoch: 4 [42240/60000 (70%)]\tloss_supervised_1: 0.010859, loss_supervised_2: 0.008721\n",
            "Train Epoch: 4 [42880/60000 (71%)]\tloss_supervised_1: 0.005287, loss_supervised_2: 0.002962\n",
            "Train Epoch: 4 [43520/60000 (72%)]\tloss_supervised_1: 0.001787, loss_supervised_2: 0.001238\n",
            "Train Epoch: 4 [44160/60000 (74%)]\tloss_supervised_1: 0.007395, loss_supervised_2: 0.001999\n",
            "Train Epoch: 4 [44800/60000 (75%)]\tloss_supervised_1: 0.043506, loss_supervised_2: 0.038037\n",
            "Train Epoch: 4 [45440/60000 (76%)]\tloss_supervised_1: 0.001958, loss_supervised_2: 0.000471\n",
            "Train Epoch: 4 [46080/60000 (77%)]\tloss_supervised_1: 0.052362, loss_supervised_2: 0.043229\n",
            "Train Epoch: 4 [46720/60000 (78%)]\tloss_supervised_1: 0.041049, loss_supervised_2: 0.033338\n",
            "Train Epoch: 4 [47360/60000 (79%)]\tloss_supervised_1: 0.001781, loss_supervised_2: 0.001007\n",
            "Train Epoch: 4 [48000/60000 (80%)]\tloss_supervised_1: 0.055564, loss_supervised_2: 0.068485\n",
            "Train Epoch: 4 [48640/60000 (81%)]\tloss_supervised_1: 0.155050, loss_supervised_2: 0.192369\n",
            "Train Epoch: 4 [49280/60000 (82%)]\tloss_supervised_1: 0.058003, loss_supervised_2: 0.084824\n",
            "Train Epoch: 4 [49920/60000 (83%)]\tloss_supervised_1: 0.065268, loss_supervised_2: 0.088247\n",
            "Train Epoch: 4 [50560/60000 (84%)]\tloss_supervised_1: 0.004469, loss_supervised_2: 0.003527\n",
            "Train Epoch: 4 [51200/60000 (85%)]\tloss_supervised_1: 0.039121, loss_supervised_2: 0.059700\n",
            "Train Epoch: 4 [51840/60000 (86%)]\tloss_supervised_1: 0.001321, loss_supervised_2: 0.000966\n",
            "Train Epoch: 4 [52480/60000 (87%)]\tloss_supervised_1: 0.056290, loss_supervised_2: 0.050630\n",
            "Train Epoch: 4 [53120/60000 (88%)]\tloss_supervised_1: 0.002279, loss_supervised_2: 0.001371\n",
            "Train Epoch: 4 [53760/60000 (90%)]\tloss_supervised_1: 0.006076, loss_supervised_2: 0.011436\n",
            "Train Epoch: 4 [54400/60000 (91%)]\tloss_supervised_1: 0.004649, loss_supervised_2: 0.006362\n",
            "Train Epoch: 4 [55040/60000 (92%)]\tloss_supervised_1: 0.013501, loss_supervised_2: 0.005909\n",
            "Train Epoch: 4 [55680/60000 (93%)]\tloss_supervised_1: 0.028486, loss_supervised_2: 0.026758\n",
            "Train Epoch: 4 [56320/60000 (94%)]\tloss_supervised_1: 0.085931, loss_supervised_2: 0.109477\n",
            "Train Epoch: 4 [56960/60000 (95%)]\tloss_supervised_1: 0.007579, loss_supervised_2: 0.010826\n",
            "Train Epoch: 4 [57600/60000 (96%)]\tloss_supervised_1: 0.007215, loss_supervised_2: 0.007733\n",
            "Train Epoch: 4 [58240/60000 (97%)]\tloss_supervised_1: 0.023222, loss_supervised_2: 0.061385\n",
            "Train Epoch: 4 [58880/60000 (98%)]\tloss_supervised_1: 0.004710, loss_supervised_2: 0.003700\n",
            "Train Epoch: 4 [59520/60000 (99%)]\tloss_supervised_1: 0.001408, loss_supervised_2: 0.003363\n",
            "Train Epoch: 5 [0/60000 (0%)]\tloss_supervised_1: 0.001645, loss_supervised_2: 0.001205\n",
            "Train Epoch: 5 [640/60000 (1%)]\tloss_supervised_1: 0.004016, loss_supervised_2: 0.002722\n",
            "Train Epoch: 5 [1280/60000 (2%)]\tloss_supervised_1: 0.005415, loss_supervised_2: 0.005031\n",
            "Train Epoch: 5 [1920/60000 (3%)]\tloss_supervised_1: 0.048486, loss_supervised_2: 0.044138\n",
            "Train Epoch: 5 [2560/60000 (4%)]\tloss_supervised_1: 0.003197, loss_supervised_2: 0.002360\n",
            "Train Epoch: 5 [3200/60000 (5%)]\tloss_supervised_1: 0.008999, loss_supervised_2: 0.008988\n",
            "Train Epoch: 5 [3840/60000 (6%)]\tloss_supervised_1: 0.000633, loss_supervised_2: 0.001639\n",
            "Train Epoch: 5 [4480/60000 (7%)]\tloss_supervised_1: 0.007496, loss_supervised_2: 0.015570\n",
            "Train Epoch: 5 [5120/60000 (9%)]\tloss_supervised_1: 0.013706, loss_supervised_2: 0.011133\n",
            "Train Epoch: 5 [5760/60000 (10%)]\tloss_supervised_1: 0.002524, loss_supervised_2: 0.002293\n",
            "Train Epoch: 5 [6400/60000 (11%)]\tloss_supervised_1: 0.004148, loss_supervised_2: 0.002953\n",
            "Train Epoch: 5 [7040/60000 (12%)]\tloss_supervised_1: 0.001419, loss_supervised_2: 0.001015\n",
            "Train Epoch: 5 [7680/60000 (13%)]\tloss_supervised_1: 0.003560, loss_supervised_2: 0.002914\n",
            "Train Epoch: 5 [8320/60000 (14%)]\tloss_supervised_1: 0.056906, loss_supervised_2: 0.101865\n",
            "Train Epoch: 5 [8960/60000 (15%)]\tloss_supervised_1: 0.001340, loss_supervised_2: 0.000842\n",
            "Train Epoch: 5 [9600/60000 (16%)]\tloss_supervised_1: 0.003558, loss_supervised_2: 0.005366\n",
            "Train Epoch: 5 [10240/60000 (17%)]\tloss_supervised_1: 0.000812, loss_supervised_2: 0.001474\n",
            "Train Epoch: 5 [10880/60000 (18%)]\tloss_supervised_1: 0.023512, loss_supervised_2: 0.028654\n",
            "Train Epoch: 5 [11520/60000 (19%)]\tloss_supervised_1: 0.067532, loss_supervised_2: 0.105872\n",
            "Train Epoch: 5 [12160/60000 (20%)]\tloss_supervised_1: 0.001704, loss_supervised_2: 0.000945\n",
            "Train Epoch: 5 [12800/60000 (21%)]\tloss_supervised_1: 0.004294, loss_supervised_2: 0.002680\n",
            "Train Epoch: 5 [13440/60000 (22%)]\tloss_supervised_1: 0.002545, loss_supervised_2: 0.001061\n",
            "Train Epoch: 5 [14080/60000 (23%)]\tloss_supervised_1: 0.001387, loss_supervised_2: 0.001082\n",
            "Train Epoch: 5 [14720/60000 (25%)]\tloss_supervised_1: 0.001037, loss_supervised_2: 0.000571\n",
            "Train Epoch: 5 [15360/60000 (26%)]\tloss_supervised_1: 0.057628, loss_supervised_2: 0.108557\n",
            "Train Epoch: 5 [16000/60000 (27%)]\tloss_supervised_1: 0.023170, loss_supervised_2: 0.009122\n",
            "Train Epoch: 5 [16640/60000 (28%)]\tloss_supervised_1: 0.002897, loss_supervised_2: 0.003287\n",
            "Train Epoch: 5 [17280/60000 (29%)]\tloss_supervised_1: 0.071290, loss_supervised_2: 0.118853\n",
            "Train Epoch: 5 [17920/60000 (30%)]\tloss_supervised_1: 0.000221, loss_supervised_2: 0.000257\n",
            "Train Epoch: 5 [18560/60000 (31%)]\tloss_supervised_1: 0.053567, loss_supervised_2: 0.061758\n",
            "Train Epoch: 5 [19200/60000 (32%)]\tloss_supervised_1: 0.014152, loss_supervised_2: 0.013766\n",
            "Train Epoch: 5 [19840/60000 (33%)]\tloss_supervised_1: 0.000689, loss_supervised_2: 0.000477\n",
            "Train Epoch: 5 [20480/60000 (34%)]\tloss_supervised_1: 0.001710, loss_supervised_2: 0.000913\n",
            "Train Epoch: 5 [21120/60000 (35%)]\tloss_supervised_1: 0.003346, loss_supervised_2: 0.001116\n",
            "Train Epoch: 5 [21760/60000 (36%)]\tloss_supervised_1: 0.004824, loss_supervised_2: 0.002044\n",
            "Train Epoch: 5 [22400/60000 (37%)]\tloss_supervised_1: 0.082908, loss_supervised_2: 0.123061\n",
            "Train Epoch: 5 [23040/60000 (38%)]\tloss_supervised_1: 0.033197, loss_supervised_2: 0.063594\n",
            "Train Epoch: 5 [23680/60000 (39%)]\tloss_supervised_1: 0.004352, loss_supervised_2: 0.002291\n",
            "Train Epoch: 5 [24320/60000 (41%)]\tloss_supervised_1: 0.005102, loss_supervised_2: 0.003875\n",
            "Train Epoch: 5 [24960/60000 (42%)]\tloss_supervised_1: 0.012061, loss_supervised_2: 0.008179\n",
            "Train Epoch: 5 [25600/60000 (43%)]\tloss_supervised_1: 0.000648, loss_supervised_2: 0.000450\n",
            "Train Epoch: 5 [26240/60000 (44%)]\tloss_supervised_1: 0.269076, loss_supervised_2: 0.293172\n",
            "Train Epoch: 5 [26880/60000 (45%)]\tloss_supervised_1: 0.003621, loss_supervised_2: 0.002690\n",
            "Train Epoch: 5 [27520/60000 (46%)]\tloss_supervised_1: 0.003534, loss_supervised_2: 0.001492\n",
            "Train Epoch: 5 [28160/60000 (47%)]\tloss_supervised_1: 0.001016, loss_supervised_2: 0.000988\n",
            "Train Epoch: 5 [28800/60000 (48%)]\tloss_supervised_1: 0.046173, loss_supervised_2: 0.048477\n",
            "Train Epoch: 5 [29440/60000 (49%)]\tloss_supervised_1: 0.010714, loss_supervised_2: 0.010439\n",
            "Train Epoch: 5 [30080/60000 (50%)]\tloss_supervised_1: 0.113956, loss_supervised_2: 0.124526\n",
            "Train Epoch: 5 [30720/60000 (51%)]\tloss_supervised_1: 0.008248, loss_supervised_2: 0.005410\n",
            "Train Epoch: 5 [31360/60000 (52%)]\tloss_supervised_1: 0.008926, loss_supervised_2: 0.003449\n",
            "Train Epoch: 5 [32000/60000 (53%)]\tloss_supervised_1: 0.001332, loss_supervised_2: 0.001007\n",
            "Train Epoch: 5 [32640/60000 (54%)]\tloss_supervised_1: 0.011331, loss_supervised_2: 0.015808\n",
            "Train Epoch: 5 [33280/60000 (55%)]\tloss_supervised_1: 0.079019, loss_supervised_2: 0.076139\n",
            "Train Epoch: 5 [33920/60000 (57%)]\tloss_supervised_1: 0.022833, loss_supervised_2: 0.042118\n",
            "Train Epoch: 5 [34560/60000 (58%)]\tloss_supervised_1: 0.093026, loss_supervised_2: 0.114329\n",
            "Train Epoch: 5 [35200/60000 (59%)]\tloss_supervised_1: 0.005575, loss_supervised_2: 0.003097\n",
            "Train Epoch: 5 [35840/60000 (60%)]\tloss_supervised_1: 0.005022, loss_supervised_2: 0.005695\n",
            "Train Epoch: 5 [36480/60000 (61%)]\tloss_supervised_1: 0.012229, loss_supervised_2: 0.034037\n",
            "Train Epoch: 5 [37120/60000 (62%)]\tloss_supervised_1: 0.048865, loss_supervised_2: 0.056804\n",
            "Train Epoch: 5 [37760/60000 (63%)]\tloss_supervised_1: 0.049923, loss_supervised_2: 0.050380\n",
            "Train Epoch: 5 [38400/60000 (64%)]\tloss_supervised_1: 0.001395, loss_supervised_2: 0.000625\n",
            "Train Epoch: 5 [39040/60000 (65%)]\tloss_supervised_1: 0.065517, loss_supervised_2: 0.098426\n",
            "Train Epoch: 5 [39680/60000 (66%)]\tloss_supervised_1: 0.100193, loss_supervised_2: 0.105041\n",
            "Train Epoch: 5 [40320/60000 (67%)]\tloss_supervised_1: 0.001201, loss_supervised_2: 0.000843\n",
            "Train Epoch: 5 [40960/60000 (68%)]\tloss_supervised_1: 0.001173, loss_supervised_2: 0.002094\n",
            "Train Epoch: 5 [41600/60000 (69%)]\tloss_supervised_1: 0.066353, loss_supervised_2: 0.079989\n",
            "Train Epoch: 5 [42240/60000 (70%)]\tloss_supervised_1: 0.000106, loss_supervised_2: 0.000120\n",
            "Train Epoch: 5 [42880/60000 (71%)]\tloss_supervised_1: 0.033194, loss_supervised_2: 0.034869\n",
            "Train Epoch: 5 [43520/60000 (72%)]\tloss_supervised_1: 0.022888, loss_supervised_2: 0.014644\n",
            "Train Epoch: 5 [44160/60000 (74%)]\tloss_supervised_1: 0.027320, loss_supervised_2: 0.027617\n",
            "Train Epoch: 5 [44800/60000 (75%)]\tloss_supervised_1: 0.055784, loss_supervised_2: 0.087296\n",
            "Train Epoch: 5 [45440/60000 (76%)]\tloss_supervised_1: 0.000857, loss_supervised_2: 0.000666\n",
            "Train Epoch: 5 [46080/60000 (77%)]\tloss_supervised_1: 0.046896, loss_supervised_2: 0.067397\n",
            "Train Epoch: 5 [46720/60000 (78%)]\tloss_supervised_1: 0.000358, loss_supervised_2: 0.000518\n",
            "Train Epoch: 5 [47360/60000 (79%)]\tloss_supervised_1: 0.013446, loss_supervised_2: 0.010456\n",
            "Train Epoch: 5 [48000/60000 (80%)]\tloss_supervised_1: 0.009469, loss_supervised_2: 0.009858\n",
            "Train Epoch: 5 [48640/60000 (81%)]\tloss_supervised_1: 0.023394, loss_supervised_2: 0.037357\n",
            "Train Epoch: 5 [49280/60000 (82%)]\tloss_supervised_1: 0.000544, loss_supervised_2: 0.000544\n",
            "Train Epoch: 5 [49920/60000 (83%)]\tloss_supervised_1: 0.002542, loss_supervised_2: 0.001450\n",
            "Train Epoch: 5 [50560/60000 (84%)]\tloss_supervised_1: 0.000597, loss_supervised_2: 0.000991\n",
            "Train Epoch: 5 [51200/60000 (85%)]\tloss_supervised_1: 0.024467, loss_supervised_2: 0.027780\n",
            "Train Epoch: 5 [51840/60000 (86%)]\tloss_supervised_1: 0.046455, loss_supervised_2: 0.052164\n",
            "Train Epoch: 5 [52480/60000 (87%)]\tloss_supervised_1: 0.005282, loss_supervised_2: 0.006246\n",
            "Train Epoch: 5 [53120/60000 (88%)]\tloss_supervised_1: 0.006509, loss_supervised_2: 0.007238\n",
            "Train Epoch: 5 [53760/60000 (90%)]\tloss_supervised_1: 0.008298, loss_supervised_2: 0.010743\n",
            "Train Epoch: 5 [54400/60000 (91%)]\tloss_supervised_1: 0.066711, loss_supervised_2: 0.079644\n",
            "Train Epoch: 5 [55040/60000 (92%)]\tloss_supervised_1: 0.174273, loss_supervised_2: 0.191399\n",
            "Train Epoch: 5 [55680/60000 (93%)]\tloss_supervised_1: 0.054639, loss_supervised_2: 0.072333\n",
            "Train Epoch: 5 [56320/60000 (94%)]\tloss_supervised_1: 0.000595, loss_supervised_2: 0.000854\n",
            "Train Epoch: 5 [56960/60000 (95%)]\tloss_supervised_1: 0.047528, loss_supervised_2: 0.051022\n",
            "Train Epoch: 5 [57600/60000 (96%)]\tloss_supervised_1: 0.010680, loss_supervised_2: 0.007667\n",
            "Train Epoch: 5 [58240/60000 (97%)]\tloss_supervised_1: 0.009374, loss_supervised_2: 0.006914\n",
            "Train Epoch: 5 [58880/60000 (98%)]\tloss_supervised_1: 0.013633, loss_supervised_2: 0.025594\n",
            "Train Epoch: 5 [59520/60000 (99%)]\tloss_supervised_1: 0.005976, loss_supervised_2: 0.002473\n",
            "Max entropy given\n",
            "\n",
            "Test: Avg. loss: 0.0384, Accuracy: 9872/10000 (99%)\n",
            "\n",
            "True y given\n",
            "\n",
            "Test: Avg. loss: 0.0076, Accuracy: 9971/10000 (100%)\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(99.7100, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,))\n",
        "])\n",
        "train_dataset = datasets.MNIST('data', train=True, download=True, transform=transform)\n",
        "test_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)\n",
        "\n",
        "f = Net().to(device)\n",
        "optimizer = optim.Adam(f.parameters(), lr=1e-3)\n",
        "\n",
        "test(f, test_loader)\n",
        "train(f, train_loader, optimizer, n_epochs)\n",
        "test(f, test_loader)\n",
        "test(f, test_loader, with_true_y=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiLqjF6N-NbB"
      },
      "source": [
        "## ITTT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "XyLV6mn7-NbB"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def ttt_one_instance(x, f_ttt, f, optimizer, n_steps, y, n_classes=10):\n",
        "  f_ttt.load_state_dict(f.state_dict())  # reset f_ttt to f\n",
        "  f_ttt.train()\n",
        "  for step in range(n_steps + 1):\n",
        "\n",
        "    y0 = F.one_hot(torch.randint(0, n_classes, (x.shape[0],), device=device), num_classes=n_classes).float()\n",
        "    y1, z1 = f_ttt(x, y0)\n",
        "    y2, z2 = f.f2(z1, y1)\n",
        "\n",
        "    loss_unsupervised_y = js_div(y1, y2)\n",
        "    loss_unsupervised_z = (z1 - z2).pow(2).mean()\n",
        "    loss = loss_unsupervised_y #+ loss_unsupervised_z\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    if f_ttt.f2.fc2.weight.grad.var() == 0:\n",
        "        pass\n",
        "    optimizer.step()\n",
        "  return y1, y2\n",
        "\n",
        "def ttt(f, test_loader, n_steps, lr):\n",
        "  f_ttt = deepcopy(f)\n",
        "  f.eval()\n",
        "  optimizer = optim.Adam(f_ttt.parameters(), lr=lr)\n",
        "  test_loss_1, correct_1 = 0, 0\n",
        "  test_loss_2, correct_2 = 0, 0\n",
        "\n",
        "  for ind, (data, target) in tqdm(enumerate(test_loader), total=len(test_loader)):\n",
        "    # print(f'batch {ind}/{len(test_loader)}:')\n",
        "    x, y = data.to(device), target.to(device)\n",
        "    y_hat_1, y_hat_2 = ttt_one_instance(x, f_ttt, f, optimizer, n_steps, y)\n",
        "\n",
        "    test_loss_1 += F.nll_loss(y_hat_1.log(), y, size_average=False).item()\n",
        "    test_loss_2 += F.nll_loss(y_hat_2.log(), y, size_average=False).item()\n",
        "\n",
        "    pred_1 = y_hat_1.data.max(1, keepdim=True)[1]\n",
        "    pred_2 = y_hat_2.data.max(1, keepdim=True)[1]\n",
        "\n",
        "    correct_1 += pred_1.eq(y.data.view_as(pred_1)).sum()\n",
        "    correct_2 += pred_2.eq(y.data.view_as(pred_2)).sum()\n",
        "\n",
        "  return correct_1 / len(test_loader.dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "qazvvdKD-NbB"
      },
      "outputs": [],
      "source": [
        "class AddGaussianNoise(object):\n",
        "    def __init__(self, std, mean=0.):\n",
        "        self.std = std\n",
        "        self.mean = mean\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        return tensor + torch.randn(tensor.size()) * self.std + self.mean\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.1307,), (0.3081,)),\n",
        "    AddGaussianNoise(1.5)])\n",
        "ood_dataset = datasets.MNIST('data', train=False, download=True, transform=transform)\n",
        "ood_loader = torch.utils.data.DataLoader(ood_dataset, batch_size=64, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "MiQn-Ry3-NbD",
        "outputId": "40202270-65e4-4281-8492-db4be7288c77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:05<00:00, 29.54it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8090, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "ttt(f, ood_loader, n_steps=0, lr=0.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_IpKo9xf-NbH",
        "outputId": "2040bd71-d7ec-463e-9cc6-ec934af3d5dd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 157/157 [00:19<00:00,  8.02it/s]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.8709, device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "ttt(f, ood_loader, n_steps=10, lr=1e-3)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}